---
title: "05a_Grouped_MIRT_Analysis"
author: "Leigh Allison"
date: "August 20, 2018"
output: html_document
---

#High Performance Computing
In order to analyze the entire dataset of 56 countries and 213 variables, we needed to use high performance computing in order to access hardware with enough continous memory. The parameters, loadings, and scores are calculated using cloud computing and then are able to be loaded onto a normal desktop computer for analysis. This script was run a computer with 500GB of RAM. 

```{r Load required packages}
library(mirt)
library(parallel)
library(multilevel)
```


Now load Individual data from 02_Cleaning_WVS code 
```{r Load Data file}
#(Pick one subset of countries to analyze)
#1. All 56 Countries
Individual_MIRTData <- read.csv("Individual_MIRTData_051118.csv")

#2. Wealthy Industrialized Countries - Austrailia, Germany, Japan, Spain, Sweden, and the US
#Individual_MIRTData <- read.csv("WealthySubset_Individual_MIRTData.csv")

Individual_MIRTData <- Individual_MIRTData[,c(2:216)]

#Useful in determining if items have high differential ability in just one dimensions. This is a crude first pass at understand the correlations in the data.
Item_Total_Correlations <- item.total(Individual_MIRTData[,c(3:215)])

i=1
World_Individual_MIRTData <-Individual_MIRTData[,c(3:215)]
World_Spread_Comparison<-c()
QuestionstoCombine<-c()
itemtype <- c()
itemT = 0

for(i in 1:213){
  Count_World <- as.data.frame(table(World_Individual_MIRTData[i]))
  Precentage_World <-round((Count_World$Freq/sum(Count_World$Freq))*100,2)
  n<-nrow(Count_World)
  if(n==2){itemT='2PL'}else{itemT='graded'}
  itemtype <- rbind(itemtype, itemT)
    for(j in 1:n){
    if(Precentage_World[j]<=5.00){
      LowCategory <- colnames(World_Individual_MIRTData[i])
    }else{LowCategory=NA}
    QuestionstoCombine<-cbind(QuestionstoCombine, LowCategory)
  }
  
}

itemT <- rep('graded', 213) #Ordered 
itemT[1:22] <- 'nominal' #Categorical
itemT[23:58] <- '2PL' #Binary

Data_Itemtype <- rbind(colnames(Individual_MIRTData[,c(3:215)]),itemT)
write.csv(Data_Itemtype, "Data_ItemType.csv")

Combine <- as.data.frame(unique(na.omit(t(QuestionstoCombine))))
Combine <- as.character(Combine$V1)
#as a crude method these questions could be removed to test the fit of the questions

World_Individual_MIRTData <-Individual_MIRTData[,!colnames(Individual_MIRTData) %in% Combine ]
#write.csv(World_Individual_MIRTData,"World_Individual_MIRTData.csv")

World_Individual_MIRTData <- t(World_Individual_MIRTData)
Data_Itemtype <- t(Data_Itemtype)
World_Individual_MIRTData <- merge(Data_Itemtype,World_Individual_MIRTData, 
                                   by.y=0,by.x="V1",sort=FALSE)

write.csv(World_Individual_MIRTData[,c(1,2,3)],"World_Individual_MIRTData_Itemtype.csv")
World_Individual_MIRTData$itemT


var_na <- function(x){var(x, na.rm=TRUE)}
Variance <- aggregate(Individual_MIRTData, by=list(Individual_MIRTData$V2.x) , FUN = var_na)
St_Dev <- as.data.frame(Variance^0.5)

Spilt <- split(Individual_MIRTData, Individual_MIRTData$V2.x)
#Need to store the country dataframe under country name
Coef_Names <- paste("CountryIvd", names(Spilt), sep = "_")

i=1
j=1
for(i in 1:56){#loops through the countries
  Country_Ivd_Data<- Spilt[[i]] #focuses on one country
  assign(Coef_Names[i], as.data.frame(Country_Ivd_Data))
  i=i+1
}

mean_na <- function(x){mean(x, na.rm=TRUE)} 
weighted.mean_na<-  function(x){weighted.mean(x, w=Individual_MIRTData$V258.x,na.rm=TRUE)} 

Split_CountryDF <- list(CountryIvd_12,CountryIvd_31,CountryIvd_32,CountryIvd_36,
                        CountryIvd_51,CountryIvd_76,CountryIvd_112,CountryIvd_152,
                        CountryIvd_156,CountryIvd_158,CountryIvd_170,CountryIvd_196,
                        CountryIvd_218,CountryIvd_233,CountryIvd_268,CountryIvd_275,
                        CountryIvd_276,CountryIvd_288,CountryIvd_344,CountryIvd_356,
                        CountryIvd_368,CountryIvd_392,CountryIvd_398,CountryIvd_400,
                        CountryIvd_410,CountryIvd_417,CountryIvd_422,CountryIvd_434,
                        CountryIvd_458,CountryIvd_484,CountryIvd_504,CountryIvd_528,
                        CountryIvd_554,CountryIvd_566,CountryIvd_586,CountryIvd_604,
                        CountryIvd_608,CountryIvd_616,CountryIvd_642,CountryIvd_643,
                        CountryIvd_646,CountryIvd_702,CountryIvd_705,CountryIvd_710,
                        CountryIvd_716,CountryIvd_724,CountryIvd_752,CountryIvd_764,
                        CountryIvd_780,CountryIvd_788,CountryIvd_792,CountryIvd_804,
                        CountryIvd_840,CountryIvd_858,CountryIvd_860,CountryIvd_887)

Weighted_Means <- c()
Weighted_Means_Names <- paste("WMeans", names(Spilt), sep = "_")
i=1
for(i in 1:56){
 DF <-as.data.frame(Split_CountryDF[i])
 Weighted_Mean <-apply(DF, 2,  function(x){weighted.mean(x, w=DF$V258.x,na.rm=TRUE)})
 assign(Weighted_Means_Names[i], as.data.frame(Weighted_Mean))
 Weighted_Means <- cbind(Weighted_Means, Weighted_Mean)
  i=i+1
 }
colnames( Weighted_Means ) <- Coef_Names
 Weighted_Means <- as.data.frame(t(Weighted_Means))
  
Weighted_Mean_112 <- apply(CountryIvd_112, 2,  function(x){weighted.mean(x, w=CountryIvd_112$V258.x,na.rm=TRUE)})
Mean_112 <- apply(CountryIvd_112, 2,  mean_na)

Weighted_Mean_112 = Weighted_Means$CountryIvd_112

summary(CountryIvd_32$V50)

CoV<-St_Dev[,c(2:216)]/Weighted_Means
CoV<-CoV[,c(3:215)]

rownames(St_Dev)<-Weighted_Means$"V2.x"
rownames(Weighted_Means)<-Weighted_Means$"V2.x"
rownames(CoV)<-Weighted_Means$"V2.x"

write.csv(St_Dev, "StandDev.csv")
write.csv(Weighted_Means, "Weighted_Means.csv")
write.csv(CoV,"CoefofVar.csv")
```

#Item Spread
In order for an IRT to fit parameters, all the categories in a question need to be used. Since our goal is to group them by country, we need to not only check that the categories are all used at the global level, but also at the country level. Ideally, all categories within an item will have 5 or more precent of the responses. We will start by analyzing the Science questions. If there is less than 5% in a given category it is possible to combine two categories.

##Aggregate Categories at the Country Level
We will be updating the Individual_MIRTData_test dataframe.
```{r}
#To reset the test dataframe
Individual_MIRTData_test <- Individual_MIRTData[,c("V2.x","V258.x", Science_Variables, Equality_Variables)]

Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
```

#Aggregating Categories for V153
We will start with an exampple aggr
```{r Combining Categories in V153}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V153))
Spread_Comparison <-cbind(Spread_Comparison,round((Count$Freq/sum(Count$Freq))*100,2) )  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V153_SpreadComparison_Original.csv")

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V153_1_Ref","V153_2","V153_3","V153_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V153_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V153[i]) && Individual_MIRTData_test$V153[i]==1){
    Individual_MIRTData_test$V153[i]<-2} 
  }} 
}


#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V153))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}

CombineNone
 
write.csv(Spread_Comparison_Update1, "V153_SpreadComparison_Updated1.csv")

 
#Now we need to combine 4 into 3
#Lets make a list of the countries that should have code 4 combined into category 3.
Combine4into3 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 4 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
Combine4into3
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V153[i]) && Individual_MIRTData_test$V153[i]==4){
    Individual_MIRTData_test$V153[i]<-3} 
  }} 
}

#Now double check that none of the code 4 categories are under 5%. Except now several of the countries do not have any values for code 4.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V153))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
if(nrow(Precentage)==3){
  Precentage<- rbind(Precentage, NA)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison_Update2[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone
 write.csv(Spread_Comparison_Update2, "V153_SpreadComparison_Updated2.csv")
 
 
#Now, there are still countries with less than 5% in Code 3&4 combined. We have chosen not fto further combine this with code 2 because codes 3&4 represent disagreement while code 2 represents agreement.
#Lets make a list of the countries that should have code 3 combined into category 2.
#Combine3into2 <- c()
#Country <- NA
#i=1

#for(i in 1:56){#need to loop through row 3 of spread_comparison dataframe
#  Spread_Comparison_Code3 <- Spread_Comparison_Update2[3,]
#  if(!is.na(Spread_Comparison_Code3[i]) && Spread_Comparison_Code3[i]<= 5){
#    Country <- names(Spread_Comparison_Code3[i])
#  } else { Country <- NA
#  }
#  Combine3into2<- cbind(Combine3into2 , Country)
#}
# Combine3into2 <- na.omit(t(Combine3into2))
# Combine3into2  <- as.character(Combine3into2)
#Combine3into2 #matches weighted dataframe- manually checked on 10/8/2018 by Leigh
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
#z=nrow(Individual_MIRTData_test)
#i=1
#c <- 999

#for(c in Combine3into2){#loop to combine category 1 into 2 for selected countries
# for(i in 1:z){#this loops through ALL the responses
#  if(Individual_MIRTData_test$V2.x[i]== c){
#    if(!is.na(Individual_MIRTData_test$V153[i]) && Individual_MIRTData_test$V153[i]==3){
#    Individual_MIRTData_test$V153[i]<-2} 
#  }} 
#}

```

#Aggregating Categories for V45
Sweden is the only country with a category under 5%.
```{r Combining Categories in V45}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V45))
Spread_Comparison <-cbind(Spread_Comparison,round((Count$Freq/sum(Count$Freq))*100,2) )  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V45_SpreadComparison_Original.csv")

Weighted_Spread_Comparison <- Weighted_Precentages[,c("V45_1_Ref","V45_2","V45_3")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V45_SpreadComparison_Weighted.csv")


#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V45[i]) && Individual_MIRTData_test$V45[i]==1){
    Individual_MIRTData_test$V45[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V45))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage<- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 write.csv(Spread_Comparison_Update1, "V45_SpreadComparison_Updated1.csv")
```

#Aggregating Categories for V47
528 is the only country with a category under 5%
```{r Combining Categories in V47}
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V47_1_Ref","V47_2","V47_3")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V47_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V47[i]) && Individual_MIRTData_test$V47[i]==1){
    Individual_MIRTData_test$V47[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V47))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage<- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 write.csv(Spread_Comparison_Update1, "V47_SpreadComparison_Updated1.csv")
```

#Aggregating Categories for V48
```{r Combining Categories in V48}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V48))
Spread_Comparison <-cbind(Spread_Comparison,round((Count$Freq/sum(Count$Freq))*100,2) )  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V48_SpreadComparison_Original.csv")

Weighted_Spread_Comparison <- Weighted_Precentages[,c("V48_1_Ref","V48_2","V48_3")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V48_SpreadComparison_Weighted.csv")

#Now we need to combine 3 into 2 for a handful of countries
#Lets make a list of the countries that should have code 3 combined into category 2.
Combine3into2 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code3 <- Spread_Comparison[3,]
  if(!is.na(Spread_Comparison_Code3[i]) && Spread_Comparison_Code3[i]<= 5){
    Country <- names(Spread_Comparison_Code3[i])
  } else { Country <- NA
  }
  Combine3into2<- cbind(Combine3into2 , Country)
}
 Combine3into2 <- na.omit(t(Combine3into2))
 Combine3into2  <- as.character(Combine3into2)
Combine3into2 
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine3into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V48[i]) && Individual_MIRTData_test$V48[i]==3){
    Individual_MIRTData_test$V48[i]<-2} 
  }} 
}

#Now double check that none of the code 3 categories are under 5%. Except now several of the countries do not have any values for code 4.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (l in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(l)),]
Count <- as.data.frame(table(Country_DF$V48))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(l %in% Combine3into2){
  Precentage <- rbind(Precentage, NA)
}
Spread_Comparison_Update<- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code3 <- Spread_Comparison_Update[3,]
  if(!is.na(Spread_Comparison_Code3[i]) && Spread_Comparison_Code3[i]<= 5){
    Country <- names(Spread_Comparison_Code3[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 
write.csv(Spread_Comparison_Update, "V48_SpreadComparison_Updated.csv")
```

#Aggregating Categories for V50
```{r Combining Categories in V50}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V50)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries

write.csv(Spread_Comparison, "V50_SpreadComparison_Original.csv")


Weighted_Spread_Comparison <- Weighted_Precentages[,c("V50_1_Ref","V50_2","V50_3","V50_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V50_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i] != 0 
     && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V50[i]) && Individual_MIRTData_test$V50[i]==1){
    Individual_MIRTData_test$V50[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()
Precentage <- c()

for (i in Countries){
  Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
  Count <- as.data.frame(table(Country_DF$V50))
  if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
  else if (i %in% Combine1into2){Precentage <- c(NA, round((Count$Freq/sum(Count$Freq))*100,2))}
  else {Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)}
Spread_Comparison_Update1 <-cbind(Spread_Comparison_Update1, Precentage)  
}
  
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i] != 0 && 
     Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 write.csv(Spread_Comparison_Update1, "V50_SpreadComparison_Updated1.csv")

#Now we need to combine 4 into 3
#Lets make a list of the countries that should have code 4 combined into category 3.
Combine4into3 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 4 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison[4,] #should be based off of the weighted spread_comparison
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5 && 
     Spread_Comparison_Code4[i] != 0){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
Combine4into3
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V50[i]) && Individual_MIRTData_test$V50[i]==4){
    Individual_MIRTData_test$V50[i]<-3} 
  }} 
}

#Now double check that none of the code 4 categories are under 5%. Except now several of the countries do not have any values for code 4.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V50))
  if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
  else if (i %in% Combine1into2){Precentage <- c(NA, round((Count$Freq/sum(Count$Freq))*100,2))} 
  else if (i %in% Combine4into3){Precentage <- c(round((Count$Freq/sum(Count$Freq))*100,2), NA)}
 else {Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, Precentage)  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison_Update2[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
  CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 write.csv(Spread_Comparison_Update2, "V50_SpreadComparison_Updated2.csv")
```
Argentina (#32) did not answer this questions but, there ARE cells under 5% therefore we still have to combine any categories for any country in this item.

#Aggregating Categories for V51
```{r Combining Categories in V51}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V51)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries

write.csv(Spread_Comparison, "V51_SpreadComparison_Original.csv")


Weighted_Spread_Comparison <- Weighted_Precentages[,c("V51_1_Ref","V51_2","V51_3","V51_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V51_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V51[i]) && Individual_MIRTData_test$V51[i]==1){
    Individual_MIRTData_test$V51[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V51))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}

CombineNone
 
write.csv(Spread_Comparison_Update1, "V51_SpreadComparison_Updated1.csv")

 
#Now we need to combine 4 into 3
#Lets make a list of the countries that should have code 4 combined into category 3.
Combine4into3 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
Combine4into3
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V51[i]) && Individual_MIRTData_test$V51[i]==4){
    Individual_MIRTData_test$V51[i]<-3} 
  }} 
}

#Now double check that none of the code 4 categories are under 5%. Except now several of the countries do not have any values for code 4.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V51))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
if(nrow(Precentage)==3){
  Precentage<- rbind(Precentage, NA)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison_Update2[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone
 write.csv(Spread_Comparison_Update2, "V51_SpreadComparison_Updated2.csv")
```

#Aggregating Categories for V52
```{r Combining Categories in V52}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V52)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries

write.csv(Spread_Comparison, "V52_SpreadComparison_Original.csv")

Weighted_Spread_Comparison <- Weighted_Precentages[,c("V52_1_Ref","V52_2","V52_3","V52_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V52_SpreadComparison_Weighted.csv")


#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V52[i]) && Individual_MIRTData_test$V52[i]==1){
    Individual_MIRTData_test$V52[i]<-2} 
  }} 
}


#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V52))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}

CombineNone
 
write.csv(Spread_Comparison_Update1, "V52_SpreadComparison_Updated1.csv")

#Now we need to combine 2 into 3
#Lets make a list of the countries that should have code 4 combined into category 3.
Combine2into3 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code2 <- Spread_Comparison[2,]
  if(!is.na(Spread_Comparison_Code2[i]) && Spread_Comparison_Code2[i]<= 5){
    Country <- names(Spread_Comparison_Code2[i])
  } else { Country <- NA
  }
  Combine2into3<- cbind(Combine2into3, Country)
}
 Combine2into3<- na.omit(t(Combine2into3))
 Combine2into3 <- as.character(Combine2into3)
Combine2into3
 #did not actually combine 2 into 3 because it changes the meaning of the answer from agree to disaggree

 #write.csv(Spread_Comparison_Update2, "V52_SpreadComparison_Updated2.csv")
```

#Aggregating Categories for V53
```{r Combining Categories in V53}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V53)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V53_SpreadComparison_Original.csv")

Weighted_Spread_Comparison <- Weighted_Precentages[,c("V53_1_Ref","V53_2","V53_3","V53_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V53_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V53[i]) && Individual_MIRTData_test$V53[i]==1){
    Individual_MIRTData_test$V53[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. 
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update1<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V53))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update1 <- cbind(Spread_Comparison_Update1, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update1) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update1[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}

CombineNone
 
write.csv(Spread_Comparison_Update1, "V53_SpreadComparison_Updated1.csv")
```

#Aggregating Categories for V54
```{r Combining Categories in V54}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V54)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries

write.csv(Spread_Comparison, "V54_SpreadComparison_Original.csv")

Weighted_Spread_Comparison <- Weighted_Precentages[,c("V54_1_Ref","V54_2","V54_3","V54_4")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
write.csv(Spread_Comparison, "V54_SpreadComparison_Weighted.csv")

#Now we need to combine 4 into 3
#Lets make a list of the countries that should have code 4 combined into category 3.
Combine4into3 <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
Combine4into3
 
#Now this column needs to be put back into the the big dataframe wutg tge other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V54[i]) && Individual_MIRTData_test$V54[i]==4){
    Individual_MIRTData_test$V54[i]<-3} 
  }} 
}

#Now double check that none of the code 4 categories are under 5%. Except now several of the countries do not have any values for code 4.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V54))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine4into3){
  Precentage <- rbind(Precentage,NA)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA
i=1

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code4 <- Spread_Comparison_Update[4,]
  if(!is.na(Spread_Comparison_Code4[i]) && Spread_Comparison_Code4[i]<= 5){
    Country <- names(Spread_Comparison_Code4[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
  CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 write.csv(Spread_Comparison_Update, "V54_SpreadComparison_Updated.csv")
 
#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V54[i]) && Individual_MIRTData_test$V54[i]==1){
    Individual_MIRTData_test$V54[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V54))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine4into3){
  Precentage <- rbind(Precentage,NA)
}
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update2[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update2, "V54_SpreadComparison_Updated2.csv")
```

#Aggregating Categories for V80
```{r Combining Categories in V80}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V80)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(nrow(Count)== 0){Precentage <- c(NA,NA,NA,NA)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V80_SpreadComparison_Original.csv")

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V80_1_Ref","V80_2","V80_3","V80_4","V80_5")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V80_SpreadComparison_Weighted.csv")

#Nominal Questions - CATEGORIES CANNOT BE COMBINED
```

#Aggregating Likert Questions from 10pt to 5pts
```{r}
#In order to reduce the number of parameters that need to be estimated in the IRT model, questions that are measured from 1 to 10 are reduced to a 5pt scale, where 1&2 become 1, 3&4 become 2, etc. This is done for all countries, regradless of the spread across the categories.

Likert_test2 <-Individual_MIRTData_test
Likert10ptQuestions <- c("V208","V192","V194","V195","V196","V197")

for(m in Likert10ptQuestions){
  #Likert_test <- as.vector(Likert_test2[m]) #Updates for the question that is being converted
  for(i in 1:85264){ #this loops through ALL the responses
  if(!is.na(Likert_test2[i,m])) {
    if     (Likert_test2[i,m]== 1 ||Likert_test2[i,m]==  2){Likert_test2[i,m] <- 1}  #converts all 1s & 2s into 1s
    else if(Likert_test2[i,m]== 3 ||Likert_test2[i,m]==  4){Likert_test2[i,m] <- 2}  #converts all 3s &4s into 2s
    else if(Likert_test2[i,m]== 5 ||Likert_test2[i,m]==  6){Likert_test2[i,m] <- 3}  #converts all 5s &6s into 3s
    else if(Likert_test2[i,m]== 7 ||Likert_test2[i,m]==  8){Likert_test2[i,m] <- 4}  #converts all 7s &8s into 4s
    else if(Likert_test2[i,m]== 9 ||Likert_test2[i,m]== 10){Likert_test2[i,m] <- 5}  #converts all 9s &10s into 5s
    }
   }
  }

V208_5pt <- table(Likert_test2$V208)
V208_5pt

V197_5pt <- table(Likert_test2$V197)
V197_5pt

Individual_MIRTData_test <- Likert_test2 #Now the questions have been changes from 10pt scales to 5pt scales.
```

#Aggregtion of V208
```{r Combining Categories in V208, eval=FALSE}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V208)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
if(i== "268"){Precentage <- c(Precentage,NA)}
if(i== "36") {Precentage <- c(97.07,0.48,0.41,NA,2.04)}
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V208_SpreadComparison_Original.csv")

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V208_Very.Low_Ref","V208_Low","V208_Med",
                                                      "V208_High","V208_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)
Spread_Comparison[4,"36"] <-NA
Spread_Comparison[5,"268"] <-NA

write.csv(Spread_Comparison, "V208_SpreadComparison_Weighted.csv")
```
This question is VERY skewed and therefore will be droppred from the analysis. It appears that the majority of the world believes that it is never justifable for a man to beat his wife. South Africa had the highest precentage (10%) stating it was always justifable.

#Aggregation of V192
```{r Combining Categories in V192}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V192)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
}
colnames(Spread_Comparison) <- Countries
write.csv(Spread_Comparison, "V192_SpreadComparison_Original.csv")

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V192_Very.Low_Ref","V192_Low","V192_Med",
                                                      "V192_High","V192_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V192_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V192[i]) && Individual_MIRTData_test$V192[i]==1){
    Individual_MIRTData_test$V192[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V192))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V192_SpreadComparison_Updated.csv")


#Lets make a list of the countries that should have code 1 combined into category 2.
Combine2into3 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 2 of spread_comparison dataframe
  Spread_Comparison_Code2 <- Spread_Comparison_Update[2,]
  if(Spread_Comparison_Code2[i]<= 5){
    Country <- names(Spread_Comparison_Code2[i])
  } else { Country <- NA
  }
  Combine2into3<- cbind(Combine2into3, Country)
}
 Combine2into3<- na.omit(t(Combine2into3))
 Combine2into3 <- as.character(Combine2into3)
 Combine2into3
 
 
#This list needs to be updated because of the survey weights
 
  Combine2into3 <- c("112","156","392","434","528","566","646","702","887")
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine2into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V192[i]) && Individual_MIRTData_test$V192[i]==2){
    Individual_MIRTData_test$V192[i]<-3} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V192))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
if(i %in% Combine2into3){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 2 of spread_comparison dataframe
  Spread_Comparison_Code2 <- Spread_Comparison_Update2[2,]
  if(!is.na(Spread_Comparison_Code2[i]) && Spread_Comparison_Code2[i]<= 5){
    Country <- names(Spread_Comparison_Code2[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 
write.csv(Spread_Comparison_Update2, "V192_SpreadComparison_Updated2.csv")
```

#Aggregation of V194
```{r Combining Categories in V194}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V194)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
} #will get errors in this loop if it is run after aggregating codes
colnames(Spread_Comparison) <- Countries 
write.csv(Spread_Comparison, "V194_SpreadComparison_Original.csv") 

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V194_Very.Low_Ref","V194_Low","V194_Med",
                                                      "V194_High","V194_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V194_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V194[i]) && Individual_MIRTData_test$V194[i]==1){
    Individual_MIRTData_test$V194[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V194))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V194_SpreadComparison_Updated.csv")


#Lets make a list of the countries that should have code 5  combined into category 4.
Combine5into4 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison[5,]
  if(Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
  Combine5into4 <- cbind(Combine5into4 , Country)
}
 Combine5into4 <- na.omit(t(Combine5into4 ))
 Combine5into4  <- as.character(Combine5into4)
 Combine5into4 
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine5into4){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V194[i]) && Individual_MIRTData_test$V194[i]==5){
    Individual_MIRTData_test$V194[i]<-4} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V194))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
if(i %in% Combine5into4){
  Precentage <- rbind(Precentage, NA)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison_Update2[5,]
  if(!is.na(Spread_Comparison_Code5[i]) && Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update2, "V194_SpreadComparison_Updated2.csv")
```

#Aggregation of V195
```{r Combining Categories in V195}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V195)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
} #will get errors in this loop if it is run after aggregating codes
colnames(Spread_Comparison) <- Countries 
write.csv(Spread_Comparison, "V195_SpreadComparison_Original.csv") 

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V195_Very.Low_Ref","V195_Low",
                                                      "V195_Med",
                                                      "V195_High","V195_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V195_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V195[i]) && Individual_MIRTData_test$V195[i]==1){
    Individual_MIRTData_test$V195[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V195))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V195_SpreadComparison_Updated.csv")


#Lets make a list of the countries that should have code 5  combined into category 4.
Combine5into4 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison[5,]
  if(Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
  Combine5into4 <- cbind(Combine5into4 , Country)
}
 Combine5into4 <- na.omit(t(Combine5into4 ))
 Combine5into4  <- as.character(Combine5into4)
 Combine5into4 
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine5into4){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V195[i]) && Individual_MIRTData_test$V195[i]==5){
    Individual_MIRTData_test$V195[i]<-4} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update2<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V195))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
if(i %in% Combine5into4){
  Precentage <- rbind(Precentage, NA)
}
Spread_Comparison_Update2 <- cbind(Spread_Comparison_Update2, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update2) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison_Update2[5,]
  if(!is.na(Spread_Comparison_Code5[i]) && Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update2, "V195_SpreadComparison_Updated2.csv")
```

#Aggregation of V196
```{r Combining Categories in V196}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V196)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
} #will get errors in this loop if it is run after aggregating codes
colnames(Spread_Comparison) <- Countries 
write.csv(Spread_Comparison, "V196_SpreadComparison_Original.csv") 

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V196_Very.Low_Ref","V196_Low",
                                                      "V196_Med",
                                                      "V196_High","V196_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V196_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 5  combined into category 4.
Combine5into4 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison[5,]
  if(Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
  Combine5into4 <- cbind(Combine5into4 , Country)
}
 Combine5into4 <- na.omit(t(Combine5into4 ))
 Combine5into4  <- as.character(Combine5into4)
 Combine5into4 
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine5into4){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V196[i]) && Individual_MIRTData_test$V196[i]==5){
    Individual_MIRTData_test$V196[i]<-4} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V196))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine5into4){
  Precentage <- rbind(Precentage, NA)
}
Spread_Comparison_Update<- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5<- Spread_Comparison_Update[5,]
  if(!is.na(Spread_Comparison_Code5[i]) && Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
   CombineNone<- cbind( CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V196_SpreadComparison_Updated.csv")




```

#Aggregation of V197
```{r Combining Categories in V197}
#We will now loop through all the countries to create one dataframe with all the countries as columns and the item response categories as rows.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison<-c()
Precentage <- c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V197)) 
Precentage <- round((Count$Freq/sum(Count$Freq))*100,2)
Spread_Comparison <-cbind(Spread_Comparison, Precentage)  
} #will get errors in this loop if it is run after aggregating codes
colnames(Spread_Comparison) <- Countries 
write.csv(Spread_Comparison, "V197_SpreadComparison_Original.csv") 

#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
Weighted_Spread_Comparison <- Weighted_Precentages[,c("V197_Very.Low_Ref","V197_Low",
                                                      "V197_Med",
                                                      "V197_High","V197_.Very.High")]
rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
Spread_Comparison <- t(Weighted_Spread_Comparison)

write.csv(Spread_Comparison, "V197_SpreadComparison_Weighted.csv")


#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2
 
#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow(Individual_MIRTData_test)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if(Individual_MIRTData_test$V2.x[i]== c){
    if(!is.na(Individual_MIRTData_test$V197[i]) && Individual_MIRTData_test$V197[i]==1){
    Individual_MIRTData_test$V197[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1.
Countries <- as.character(unique(Individual_MIRTData_test$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_test[which(Individual_MIRTData_test$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V197))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine1into2){
  Precentage <- rbind(NA, Precentage)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V197_SpreadComparison_Updated.csv")

```

```{r}
#Run on 10/15/18 at 1:54, all aggregation was run on ordered questions and likert quesitons were recoded to 5pt scale and aggregated as needed. T
#write.csv(Individual_MIRTData_test, "Individual_MIRTData_AggregateUpdate.csv")
```

Since country is considered a significant external factor that could explain some of the varition in a person's response pattern, we can model the country in IRT by modelling each country separately but constaining the factors to be equal across the countries.
```{r Sci_Equ Grouped MIRT}
Individual_MIRTData<- read.csv("Individual_MIRTData_NBO198.csv")

Science_Variables <- c("V153","V192", "V194","V195","V196","V197")
Equality_Variables <- c("V45", "V47","V48","V50","V51","V52","V53","V54","V80")

Individual_MIRTData_test <- Individual_MIRTData[,c("V2.x","V258.x", Equality_Variables, Science_Variables)]

#now run the aggregation codes

itemT <- c("graded","graded","graded","graded",
           "graded","graded","graded","graded","graded",
           "graded","graded","graded","graded","nominal")


Large<- multipleGroup(Individual_MIRTData_test[,c(3:11,13:17)], 
                                                  model = 2,
                                                  group = as.character(Individual_MIRTData_test$V2.x),
                                                  rotate = "none",
                                                  invariance = c("slopes","intercepts", "free_means"), 
                                                  itemtype=itemT,
                                                  method = "EM", pars=starting_parameters,TOL=0.009,
                                                  technical = list(NCYCLES = 10, removeEmptyRows=TRUE),
                                                  survey.weights = Individual_MIRTData_test$V258.x, large=TRUE)




SciEqu_MIRT_Grouped4 <- multipleGroup(Individual_MIRTData_test[,c(3:11,13:17)], 
                                                  model = 2,
                                                  group = as.character(Individual_MIRTData_test$V2.x),
                                                  rotate = "none",
                                                  invariance = c("slopes","intercepts", "free_means"), 
                                                  itemtype=itemT,
                                                  method = "EM", pars=starting_parameters,TOL=0.009,
                                                  technical = list(NCYCLES = 10, removeEmptyRows=TRUE),
                                                  survey.weights = Individual_MIRTData_test$V258.x, large=Large)

#When large was added
#Error in is.nan(scores) : default method not implemented for type 'list'

#could be the combination of items


starting_parameters <- mod2values(SciEqu_MIRT_Grouped)
fscores(SciEqu_MIRT_Grouped)
summary(SciEqu_MIRT_Grouped)
coef(SciEqu_MIRT_Grouped , printSE=TRUE)

SciEqu_MIRT_Grouped@Fit$AIC
SciEqu_MIRT_Grouped@Fit$BIC

#This could be do to the fact that the within each item not all countries use all of the categories evenly.



DIFresult <- DIF(SciEqu_MIRT_Grouped, c("a1","a2"), plotdif = TRUE)


```

#Aggregating Likert Questions from 10pt to 5pts
This is done to reduce the number of parameters that need to be estimated by the model. 
```{r}
#In order to reduce the number of parameters that need to be estimated in the IRT model, questions that are measured from 1 to 10 are reduced to a 5pt scale, where 1&2 become 1, 3&4 become 2, etc. This is done for all countries, regradless of the spread across the categories.

Likert_5pt_Conversion <-Individual_MIRTData
Likert10ptQuestions <- colnames(Individual_MIRTData[,c(174:215)])

for(m in Likert10ptQuestions){
  #Likert_test <- as.vector(Likert_test2[m]) #Updates for the question that is being converted
  for(i in 1:85264){ #this loops through ALL the responses
  if(!is.na(Likert_5pt_Conversion[i,m])) {
    if     (Likert_5pt_Conversion[i,m]== 1 ||Likert_5pt_Conversion[i,m]==  2)
                {Likert_5pt_Conversion[i,m] <- 1}  #converts all 1s & 2s into 1s
    else if(Likert_5pt_Conversion[i,m]== 3 ||Likert_5pt_Conversion[i,m]==  4)
                {Likert_5pt_Conversion[i,m] <- 2}  #converts all 3s &4s into 2s
    else if(Likert_5pt_Conversion[i,m]== 5 ||Likert_5pt_Conversion[i,m]==  6)
            {Likert_5pt_Conversion[i,m] <- 3}  #converts all 5s &6s into 3s
    else if(Likert_5pt_Conversion[i,m]== 7 ||Likert_5pt_Conversion[i,m]==  8)
            {Likert_5pt_Conversion[i,m] <- 4}  #converts all 7s &8s into 4s
    else if(Likert_5pt_Conversion[i,m]== 9 ||Likert_5pt_Conversion[i,m]== 10)
            {Likert_5pt_Conversion[i,m] <- 5}  #converts all 9s &10s into 5s
    }
   }
  }

V23_5pt <- table(Likert_5pt_Conversion$V23)
V23_5pt

V208_5pt <- table(Likert_5pt_Conversion$V208)
V208_5pt

V197_5pt <- table(Likert_5pt_Conversion$V197)
V197_5pt

V196_5pt <- table(Likert_5pt_Conversion$V196)
V196_5pt

Individual_MIRTData_Converted<- Likert_5pt_Conversion #Now the questions have been changes from 10pt scales to 5pt, no other questions have been aggregated in this dataframe. We will need to rerun the sci_equ aggregate scripts on this dataframe to condense the codes fro particular countries.

#write.csv(Individual_MIRTData_Converted, "Individual_MIRTData_Converted.csv")
```

#National Precentages (Weighted by Country)
In order to aggregate response categories, we must first know the precentage of people who responded to each questions. Since each respondant is weighted, we will need to use the National Precentage dataframe rather than the just counting each response as one. In order to reduce the number of parameters which must be calculated, we converted the 10pt likert scale quesitons into 5pts. 

The goal is to loop through all the questions and combine categories that are less than 5% within a country. The category should only be changed for that country and by recoding the responses the scale for that country becomes smaller. 

```{r}
#Weighted_Precentages <-read.csv("WVS_Data_Percentages.csv")
#Individual_MIRTData_Converted <- read.csv("Individual_MIRTData_Converted.csv")
#Individual_MIRTData_Converted_AutoCombine <- Individual_MIRTData_Converted[,c(2:216)]
#write.csv(Individual_MIRTData_Converted_AutoCombine, "Individual_MIRTData_Converted_AutoCombineStep0.csv")
```

#Automatically Combine 1into2 and 5into4
if category has less than 5% Note(61,62,63 are not included in this dataframe because they were aggregated in the National Precentages dataframe). We will bring in the code to calculate the weighted % and then evaluate if 61,62,or 63 need to be adjusted. 
```{r AutoCombine1into2and5into4}
AutoCombine1into2and5into4=colnames(Individual_MIRTData_Converted_AutoCombine[,c(133:140,174:215)])
AutoCombine_CountriesbyQuestion <- as.data.frame(colnames(Individual_MIRTData_Converted_AutoCombine[,c(AutoCombine1into2and5into4)]))
q=1

for (p in AutoCombine1into2and5into4){
  
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #Lets make a list of the countries that should have code 1 combined into category 2.
      Combine1into2 <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Combine1into2<- cbind(Combine1into2, Country)
      }
      Combine1into2<- na.omit(t(Combine1into2))
      Combine1into2 <- as.character(Combine1into2)
      Combine1into2_List <- paste(Combine1into2, sep=" ", collapse = ",") 
      #these are the countries that have less than 5% in category one for the selected question. 
      AutoCombine_CountriesbyQuestion$Countries1into2[q]<- list(c(Combine1into2_List))
         
      #Now this column needs to be put back into the the big dataframe with the other items(columns) 
      #and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.

        z=nrow(Individual_MIRTData_Converted_AutoCombine)
        i=1
        c <- 999

        for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
         for(i in 1:z){#this loops through ALL the responses
          if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                   Individual_MIRTData_Converted_AutoCombine[i,p]==1){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-2} 
          }} 
        }
      
        #Lets make a list of the countries that should have code 5  combined into category 4.
          Combine5into4 <- c()
          Country <- NA
          for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
            Spread_Comparison_Code5 <- Spread_Comparison[5,]
            if(Spread_Comparison_Code5[i]<= 5){
              Country <- names(Spread_Comparison_Code5[i])
            } else { Country <- NA
            }
            Combine5into4 <- cbind(Combine5into4 , Country)
          }
           Combine5into4 <- na.omit(t(Combine5into4 ))
           Combine5into4  <- as.character(Combine5into4)
           Combine5into4_List <- paste(Combine5into4, sep=" ", collapse = ",") 
            #these are the countries that have less than 5% in category one for the selected question. 
             AutoCombine_CountriesbyQuestion$Countries5into4[q]<- list(c(Combine5into4_List))
             q=q+1
 
      #Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
             z=nrow(Individual_MIRTData_Converted_AutoCombine)
             i=1
             c <- 999

             for(c in Combine5into4){#loop to combine category 1 into 2 for selected countries
              for(i in 1:z){#this loops through ALL the responses
               if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                 if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                    Individual_MIRTData_Converted_AutoCombine[i,p]==5){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-4} 
               }} 
             }
 } #end of question, loop to the begining

AutoCombine1into2and5into4 <-AutoCombine_CountriesbyQuestion
Individual_MIRTData_Converted_AutoCombineStep1 <- Individual_MIRTData_Converted_AutoCombine

#Now double check that none of the code 5 categories are under 5%. Except now several of the countries do not have any values for code 5. We are checking question V196 because it's the last in the list
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update<-c()

for (i in Countries){
Country_DF <- Individual_MIRTData_Converted_AutoCombine[
      which(Individual_MIRTData_Converted_AutoCombine$V2.x %in% c(i)),]
Count <- as.data.frame(table(Country_DF$V196))
Precentage <- as.data.frame( round((Count$Freq/sum(Count$Freq))*100,2))
if(i %in% Combine5into4){
  Precentage <- rbind(Precentage,NA)
}
Spread_Comparison_Update <- cbind(Spread_Comparison_Update, 
                                   Precentage$`round((Count$Freq/sum(Count$Freq)) * 100, 2)` )  
}
colnames(Spread_Comparison_Update) <- Countries

#Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
```


#Automatically Combine 1into2 and 4into3
if category has less than 5%  
```{r AutoCombine1into2and4into3}



AutoCombine1into2and4into3<-colnames(Individual_MIRTData_Converted_AutoCombine[,                                                                          c(67:71,82:86,89,90:94,97,101,107:124,125:128,129,144:147,                                                         148,149:153,154:157,158:163,164:173)])

AutoCombine_CountriesbyQuestion <- as.data.frame(colnames(Individual_MIRTData_Converted_AutoCombine[,c(AutoCombine1into2and4into3)]))
q=1

for (p in AutoCombine1into2and4into3){
  
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #Lets make a list of the countries that should have code 1 combined into category 2.
      Combine1into2 <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Combine1into2<- cbind(Combine1into2, Country)
      }
      Combine1into2<- na.omit(t(Combine1into2))
      Combine1into2 <- as.character(Combine1into2)
      Combine1into2_List <- paste(Combine1into2, sep=" ", collapse = ",") 
      #these are the countries that have less than 5% in category one for the selected question. 
      AutoCombine_CountriesbyQuestion$Countries1into2[q]<- list(c(Combine1into2_List))
         
      #Now this column needs to be put back into the the big dataframe with the other items(columns) 
      #and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.

        z=nrow(Individual_MIRTData_Converted_AutoCombine)
        i=1
        c <- 999

        for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
         for(i in 1:z){#this loops through ALL the responses
          if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                   Individual_MIRTData_Converted_AutoCombine[i,p]==1){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-2} 
          }} 
        }
      
        #Lets make a list of the countries that should have code 5  combined into category 4.
          Combine4into3 <- c()
          Country <- NA
          for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
            Spread_Comparison_Code4 <- Spread_Comparison[4,]
            if(Spread_Comparison_Code4[i]<= 5){
              Country <- names(Spread_Comparison_Code4[i])
            } else { Country <- NA
            }
            Combine4into3 <- cbind(Combine4into3, Country)
          }
           Combine4into3 <- na.omit(t(Combine4into3 ))
           Combine4into3  <- as.character(Combine4into3)
           Combine4into3_List <- paste(Combine4into3, sep=" ", collapse = ",") 
            #these are the countries that have less than 5% in category one for the selected question. 
             AutoCombine_CountriesbyQuestion$Countries4into3[q]<- list(c(Combine4into3_List))
             q=q+1
 
      #Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
             z=nrow(Individual_MIRTData_Converted_AutoCombine)
             i=1
             c <- 999

             for(c in Combine4into3){#loop to combine category 1 into 2 for selected countries
              for(i in 1:z){#this loops through ALL the responses
               if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                 if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                    Individual_MIRTData_Converted_AutoCombine[i,p]==4){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-3} 
               }} 
             }
 } #end of question, loop to the begining

AutoCombine1into2and4into3 <- AutoCombine_CountriesbyQuestion


Individual_MIRTData_Converted_AutoCombineStep2 <- Individual_MIRTData_Converted_AutoCombine
```

#Automatically Combine 1into2 and 6into5
if category has less than 5%  
```{r AutoCombine1into2and6into5}
AutoCombine1into2and6into5<-colnames(Individual_MIRTData_Converted_AutoCombine[,                                                                          c(72:81)])

AutoCombine_CountriesbyQuestion <- as.data.frame(colnames(Individual_MIRTData_Converted_AutoCombine[,c(AutoCombine1into2and6into5)]))
q=1

for (p in AutoCombine1into2and6into5){
  
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #Lets make a list of the countries that should have code 1 combined into category 2.
      Combine1into2 <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Combine1into2<- cbind(Combine1into2, Country)
      }
      Combine1into2<- na.omit(t(Combine1into2))
      Combine1into2 <- as.character(Combine1into2)
      Combine1into2_List <- paste(Combine1into2, sep=" ", collapse = ",") 
      #these are the countries that have less than 5% in category one for the selected question. 
      AutoCombine_CountriesbyQuestion$Countries1into2[q]<- list(c(Combine1into2_List))
         
      #Now this column needs to be put back into the the big dataframe with the other items(columns) 
      #and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.

        z=nrow(Individual_MIRTData_Converted_AutoCombine)
        i=1
        c <- 999

        for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
         for(i in 1:z){#this loops through ALL the responses
          if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                   Individual_MIRTData_Converted_AutoCombine[i,p]==1){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-2} 
          }} 
        }
      
        #Lets make a list of the countries that should have code 5  combined into category 4.
          Combine6into5 <- c()
          Country <- NA
          for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
            Spread_Comparison_Code6 <- Spread_Comparison[6,]
            if(Spread_Comparison_Code6[i]<= 5){
              Country <- names(Spread_Comparison_Code6[i])
            } else { Country <- NA
            }
            Combine6into5<- cbind(Combine6into5, Country)
          }
           Combine6into5 <- na.omit(t(Combine6into5))
           Combine6into5  <- as.character(Combine6into5)
           Combine6into5_List <- paste(Combine6into5, sep=" ", collapse = ",") 
            #these are the countries that have less than 5% in category one for the selected question. 
             AutoCombine_CountriesbyQuestion$Countries6into5[q]<- list(c(Combine6into5_List))
             q=q+1
 
      #Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
             z=nrow(Individual_MIRTData_Converted_AutoCombine)
             i=1
             c <- 999

             for(c in Combine6into5){#loop to combine category 1 into 2 for selected countries
              for(i in 1:z){#this loops through ALL the responses
               if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                 if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                    Individual_MIRTData_Converted_AutoCombine[i,p]==6){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-5} 
               }} 
             }
 } #end of question, loop to the begining

AutoCombine1into2and6into5 <-AutoCombine_CountriesbyQuestion
Individual_MIRTData_Converted_AutoCombineStep3 <- Individual_MIRTData_Converted_AutoCombine
```


#Automatically Combine 1into2 and 7into6
if category has less than 5%  
```{r AutoCombine1into2and7into6}
AutoCombine1into2and7into6<-colnames(Individual_MIRTData_Converted_AutoCombine[,                                                                          c(142:143)])

AutoCombine_CountriesbyQuestion <- as.data.frame(colnames(Individual_MIRTData_Converted_AutoCombine[,c(AutoCombine1into2and7into6)]))
q=1

for (p in AutoCombine1into2and7into6){
  
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #Lets make a list of the countries that should have code 1 combined into category 2.
      Combine1into2 <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Combine1into2<- cbind(Combine1into2, Country)
      }
      Combine1into2<- na.omit(t(Combine1into2))
      Combine1into2 <- as.character(Combine1into2)
      Combine1into2_List <- paste(Combine1into2, sep=" ", collapse = ",") 
      #these are the countries that have less than 5% in category one for the selected question. 
      AutoCombine_CountriesbyQuestion$Countries1into2[q]<- list(c(Combine1into2_List))
         
      #Now this column needs to be put back into the the big dataframe with the other items(columns) 
      #and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.

        z=nrow(Individual_MIRTData_Converted_AutoCombine)
        i=1
        c <- 999

        for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
         for(i in 1:z){#this loops through ALL the responses
          if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                   Individual_MIRTData_Converted_AutoCombine[i,p]==1){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-2} 
          }} 
        }
      
        #Lets make a list of the countries that should have code 7 combined into category 6.
          Combine7into6 <- c()
          Country <- NA
          for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
            Spread_Comparison_Code7 <- Spread_Comparison[7,]
            if(Spread_Comparison_Code7[i]<= 5){
              Country <- names(Spread_Comparison_Code7[i])
            } else { Country <- NA
            }
            Combine7into6<- cbind(Combine7into6, Country)
          }
           Combine7into6 <- na.omit(t(Combine7into6))
           Combine7into6  <- as.character(Combine7into6)
           Combine7into6_List <- paste(Combine7into6, sep=" ", collapse = ",") 
            #these are the countries that have less than 5% in category one for the selected question. 
             AutoCombine_CountriesbyQuestion$Countries7into6[q]<- list(c(Combine7into6_List))
             q=q+1

             #Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
             z=nrow(Individual_MIRTData_Converted_AutoCombine)
             i=1
             c <- 999

             for(c in Combine7into6){#loop to combine category 8 into 7 for selected countries
              for(i in 1:z){#this loops through ALL the responses
               if(Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
                 if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
                    Individual_MIRTData_Converted_AutoCombine[i,p]==7){
                    Individual_MIRTData_Converted_AutoCombine[i,p]<-6} 
               }} 
             }
 } #end of question, loop to the begining

AutoCombine1into2and7into6 <-AutoCombine_CountriesbyQuestion
Individual_MIRTData_Converted_AutoCombineStep4 <- Individual_MIRTData_Converted_AutoCombine
```

#Table of Aggregated Ordered Questions
```{r Table_Ordered_LowCatPrecentage}

AutoCombine1into2and4into3_DF <- as.data.frame(AutoCombine1into2and4into3)
colnames(AutoCombine1into2and4into3_DF) <- c("Item","Combine1int2", "Combine4into3")
AutoCombine1into2and4into3_DF$Combine5into4 <- NA
AutoCombine1into2and4into3_DF$Combine6into5 <- NA
AutoCombine1into2and4into3_DF$Combine7into6 <- NA
AutoCombine1into2and4into3_DF <- AutoCombine1into2and4into3_DF[,c("Item","Combine1int2", "Combine4into3","Combine5into4","Combine6into5","Combine7into6")]

AutoCombine1into2and5into4_DF <- as.data.frame(AutoCombine1into2and5into4)
colnames(AutoCombine1into2and5into4_DF) <- c("Item","Combine1int2", "Combine5into4")
AutoCombine1into2and5into4_DF$Combine4into3 <- NA
AutoCombine1into2and5into4_DF$Combine6into5 <- NA
AutoCombine1into2and5into4_DF$Combine7into6 <- NA
AutoCombine1into2and5into4_DF <- AutoCombine1into2and5into4_DF[,c("Item","Combine1int2", "Combine4into3","Combine5into4","Combine6into5","Combine7into6")]

AutoCombine1into2and6into5_DF <- as.data.frame(AutoCombine1into2and6into5)
colnames(AutoCombine1into2and6into5_DF) <- c("Item","Combine1int2", "Combine6into5")
AutoCombine1into2and6into5_DF$Combine4into3 <- NA
AutoCombine1into2and6into5_DF$Combine5into4 <- NA
AutoCombine1into2and6into5_DF$Combine7into6 <- NA
AutoCombine1into2and6into5_DF <- AutoCombine1into2and6into5_DF[,c("Item","Combine1int2", "Combine4into3","Combine5into4","Combine6into5","Combine7into6")]

AutoCombine1into2and7into6_DF <- as.data.frame(AutoCombine1into2and7into6)
colnames(AutoCombine1into2and7into6_DF) <- c("Item","Combine1int2", "Combine7into6")
AutoCombine1into2and7into6_DF$Combine4into3 <- NA
AutoCombine1into2and7into6_DF$Combine5into4 <- NA
AutoCombine1into2and7into6_DF$Combine6into5 <- NA
AutoCombine1into2and7into6_DF <- AutoCombine1into2and7into6_DF[,c("Item","Combine1int2", "Combine4into3","Combine5into4","Combine6into5","Combine7into6")]

Ordered_LowCatPrecentage <-as.data.frame(rbind(AutoCombine1into2and4into3_DF, AutoCombine1into2and5into4_DF,
                                  AutoCombine1into2and6into5_DF, AutoCombine1into2and7into6_DF))

write.table(Ordered_LowCatPrecentage, "Ordered_LowCatPrecentage.txt")
```

#Calculations for Ordinal Questions
We need to aggregate the data into weighted sums for each country. The Likert_Count_Calc function returns a dataframe with countries as the rows and response categories 1 to 10, -1 ("I don't know"), -2 (No answer), and -6 (AdminNA). Recall that when downloaded from the WVS wesite, this data was coded with numbers to represent the response chosen or why a response is missing. For example, -5 means missing or inapporiate response, while -4 respresents not asked in that survey.  Earlier in this process (line 121), we converted -5 (inapplicable/refused/missing), -4 (not asked in survey), and -3 (not applicable), to -6 so that they are not included in the calculation. These (-6) responses represent an administractive decision; whereas -2 is when the respondant is asked the question and chooses not to answer and -1 is when the respondant answers that they do not know. This function needs to be used with the aggregate function to separate by country and in a loop to analyze multiple questions at a time. 

```{r Ordinal Questions Count Function}
Likert_Count_Calc<- function(aColumn){
 
  miss=0
  r0=0
  r1=0
  r2=0
  r3=0
  r4=0
  r5=0
  r6=0
  r7=0
  r8=0
  r9=0
  r10=0
  rneg1=0
  rneg2=0
  rneg6=0
  
  count = 1
  
for (value in aColumn){
    
    if(is.na(value)){
      miss = miss + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 0){
      r0 = r0 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 1){
      r1 = r1 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 2){
      r2 = r2 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 3){
      r3 = r3 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 4){
      r4 = r4 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 5){
      r5 = r5 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 6){
      r6 = r6 +Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 7){
      r7 = r7 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 8){
      r8 = r8 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 9){
      r9 = r9 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == 10){
      r10 = r10 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == -1){
      rneg1 = rneg1 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == -2){
      rneg2 = rneg2 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    if(value == -6){
      rneg6 = rneg6 + Individual_MIRTData_Converted_AutoCombine$V258.x[count]
      next
    }
    count = count + 1
  }
  
 dataofresponses_subset<-rbind(r0,r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, rneg1, rneg2, rneg6,miss) 
  
  #each column is a response sum, each row is coutry
  return(dataofresponses_subset)
}
```

#5 Item Likert Scale
The manual code was used to practice the code before looping it through questions of the same type.
```{r V161 Manual, eval=FALSE}
#V161
V161_Counts <- data.frame()
V161_Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine$V161, 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(V161_Country_Breakdown$x[i])) 
 V161_Counts<- as.data.frame(rbind(V161_Counts, Count))
}
row.names(V161_Counts) <- as.character(V161_Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(V161_Counts, 1, sum)) 

V161_Precent <- data.frame()
for(i in 1:56){
  Precent <- V161_Counts[i,]/country_sums$`apply(V161_Counts, 1, sum)`[i]
  V161_Precent <- rbind(V161_Precent, Precent)
}

V161_Precent<-V161_Precent[,c(1:5)]
Spread_Comparison <- t(V161_Precent*100)
write.csv(Spread_Comparison, "V161_SpreadComparison_Weighted.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine0into1 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code0 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code0[i]<= 5){
    Country <- names(Spread_Comparison_Code0[i])
  } else { Country <- NA
  }
  Combine0into1 <- cbind(Combine0into1 , Country)
}
 Combine0into1 <- na.omit(t(Combine0into1))
 Combine0into1  <- as.character(Combine0into1)
 Combine0into1

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in Combine0into1){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine$V161[i]) && 
       Individual_MIRTData_Converted_AutoCombine$V161[i]==0){
          Individual_MIRTData_Converted_AutoCombine$V161[i]<-1} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
V161_Counts <- data.frame()
V161_Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine$V161, 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(V161_Country_Breakdown$x[i])) 
 V161_Counts<- as.data.frame(rbind(V161_Counts, Count))
}
row.names(V161_Counts) <- as.character(V161_Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(V161_Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
 if(V161_Counts$r0[z] ==0){V161_Counts$r0[z] <- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update<-c()
V161_Precent <- data.frame()

for(i in 1:56){
  Precent <- V161_Counts[i,]/country_sums$`apply(V161_Counts, 1, sum)`[i]
  V161_Precent <- rbind(V161_Precent, Precent)
}

V161_Precent<-V161_Precent[,c(1:5)]
Spread_Comparison_Update <- t(V161_Precent*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code0 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code0[i]<= 5){
    Country <- names(Spread_Comparison_Code0[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V161_SpreadComparison_Updated0.csv")

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[2,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine$V161[i]) && 
       Individual_MIRTData_Converted_AutoCombine$V161[i]==1){
          Individual_MIRTData_Converted_AutoCombine$V161[i]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
V161_Counts <- data.frame()
V161_Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine$V161, 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(V161_Country_Breakdown$x[i])) 
 V161_Counts<- as.data.frame(rbind(V161_Counts, Count))
}
row.names(V161_Counts) <- as.character(V161_Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(V161_Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
 if(V161_Counts$r0[z] ==0){V161_Counts$r0[z] <- NA}
}
for (z in 1:56){ #56 countries
 if(V161_Counts$r1[z] ==0){V161_Counts$r1[z] <- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update<-c()
V161_Precent <- data.frame()

for(i in 1:56){
  Precent <- V161_Counts[i,]/country_sums$`apply(V161_Counts, 1, sum)`[i]
  V161_Precent <- rbind(V161_Precent, Precent)
}

V161_Precent<-V161_Precent[,c(1:5)]
Spread_Comparison_Update <- t(V161_Precent*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[2,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
write.csv(Spread_Comparison_Update, "V161_SpreadComparison_Updated.csv")



#Lets make a list of the countries that should have code 4 combined into category 3. (Actually 5th row)
Combine4into3 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison[5,]
  if(Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
 Combine4into3

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in  Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine$V161[i]) && 
       Individual_MIRTData_Converted_AutoCombine$V161[i]==4){
          Individual_MIRTData_Converted_AutoCombine$V161[i]<-3} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
V161_Counts <- data.frame()
V161_Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine$V161, 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(V161_Country_Breakdown$x[i])) 
 V161_Counts<- as.data.frame(rbind(V161_Counts, Count))
}
row.names(V161_Counts) <- as.character(V161_Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(V161_Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
  if(V161_Counts$r0[z] ==0){V161_Counts$r0[z]<- NA}
}
for (z in 1:56){ #56 countries
 if(V161_Counts$r1[z] ==0){V161_Counts$r1[z] <- NA}
}
for (z in 1:56){ #56 countries
  if(V161_Counts$r4[z] ==0){V161_Counts$r4[z]<- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update2<-c()
V161_Precent <- data.frame()

for(i in 1:56){
  Precent <- V161_Counts[i,]/country_sums$`apply(V161_Counts, 1, sum)`[i]
  V161_Precent <- rbind(V161_Precent, Precent)
}

V161_Precent<-V161_Precent[,c(1:5)]
Spread_Comparison_Update2 <- t(V161_Precent*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison_Update2[5,]
  if(!is.na(Spread_Comparison_Code5[i]) && Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 
write.csv(Spread_Comparison_Update2, "V161_SpreadComparison_Updated2.csv")


```

```{r V161,V162 &V163 - Auto}
FiveptLikertQuestions<- c("V161","V162","V163")

for(q in FiveptLikertQuestions){

Counts <- data.frame()
Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine[,q], 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(Country_Breakdown$x[i])) 
 Counts<- as.data.frame(rbind(Counts, Count))
}
row.names(Counts) <- as.character(Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(Counts, 1, sum))   

Precents <- data.frame()
for(i in 1:56){
  Precent <- Counts[i,]/country_sums$`apply(Counts, 1, sum)`[i]
  Precents <- rbind(Precents, Precent)
}

  Precents <-  Precents[,c(1:5)]
Spread_Comparison <- t(Precents *100)  
  
filename = paste (q,"SpreadComparison_Weighted.csv",sep="_")  
write.csv(Spread_Comparison, filename)

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine0into1 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code0 <- Spread_Comparison[1,]
  if(Spread_Comparison_Code0[i]<= 5){
    Country <- names(Spread_Comparison_Code0[i])
  } else { Country <- NA
  }
  Combine0into1 <- cbind(Combine0into1 , Country)
}
 Combine0into1 <- na.omit(t(Combine0into1))
 Combine0into1  <- as.character(Combine0into1)
 Combine0into1

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in Combine0into1){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine[i,q]) && 
       Individual_MIRTData_Converted_AutoCombine[i,q]==0){
          Individual_MIRTData_Converted_AutoCombine[i,q]<-1} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
Counts <- data.frame()
Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine[,q], 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(Country_Breakdown$x[i])) 
 Counts<- as.data.frame(rbind(Counts, Count))
}
row.names(Counts) <- as.character(Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
 if(Counts$r0[z] ==0){Counts$r0[z] <- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update<-c()
Precents <- data.frame()

for(i in 1:56){
  Precent <- Counts[i,]/country_sums$`apply(Counts, 1, sum)`[i]
  Precents <- rbind(Precents, Precent)
}

Precents<-Precents[,c(1:5)]
Spread_Comparison_Update <- t(Precents*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code0 <- Spread_Comparison_Update[1,]
  if(!is.na(Spread_Comparison_Code0[i]) && Spread_Comparison_Code0[i]<= 5){
    Country <- names(Spread_Comparison_Code0[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone
 
filename = paste (q,"SpreadComparison_Weighted_Updated0.csv",sep="_")  
write.csv(Spread_Comparison_Update, filename) 

#Lets make a list of the countries that should have code 1 combined into category 2.
Combine1into2 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[2,]
  if(Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
  Combine1into2<- cbind(Combine1into2, Country)
}
 Combine1into2<- na.omit(t(Combine1into2))
 Combine1into2 <- as.character(Combine1into2)
 Combine1into2

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in Combine1into2){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine[i,q]) && 
       Individual_MIRTData_Converted_AutoCombine[i,q]==1){
          Individual_MIRTData_Converted_AutoCombine[i,q]<-2} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
Counts <- data.frame()
Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine[,q], 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(Country_Breakdown$x[i])) 
 Counts<- as.data.frame(rbind(Counts, Count))
}
row.names(Counts) <- as.character(Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
 if(Counts$r0[z] ==0){Counts$r0[z] <- NA}
}
for (z in 1:56){ #56 countries
 if(Counts$r1[z] ==0){Counts$r1[z] <- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update<-c()
Precents <- data.frame()

for(i in 1:56){
  Precent <- Counts[i,]/country_sums$`apply(Counts, 1, sum)`[i]
  Precents <- rbind(Precents, Precent)
}

Precents<-Precents[,c(1:5)]
Spread_Comparison_Update <- t(Precents*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code1 <- Spread_Comparison_Update[2,]
  if(!is.na(Spread_Comparison_Code1[i]) && Spread_Comparison_Code1[i]<= 5){
    Country <- names(Spread_Comparison_Code1[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone

filename = paste (q,"SpreadComparison_Weighted_Updated.csv",sep="_")  
write.csv(Spread_Comparison_Update, filename) 


#Lets make a list of the countries that should have code 4 combined into category 3. (Actually 5th row)
Combine4into3 <- c()
Country <- NA
for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison[5,]
  if(Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
  Combine4into3<- cbind(Combine4into3, Country)
}
 Combine4into3<- na.omit(t(Combine4into3))
 Combine4into3 <- as.character(Combine4into3)
 Combine4into3

#Now this column needs to be put back into the the big dataframe with the other items(columns) and responses(rows). This could be done in the big dataframe by specifiying which rows to loop through.
z=nrow( Individual_MIRTData_Converted_AutoCombine)
i=1
c <- 999

for(c in  Combine4into3){#loop to combine category 1 into 2 for selected countries
 for(i in 1:z){#this loops through ALL the responses
  if( Individual_MIRTData_Converted_AutoCombine$V2.x[i]== c){
    if(!is.na( Individual_MIRTData_Converted_AutoCombine[i,q]) && 
       Individual_MIRTData_Converted_AutoCombine[i,q]==4){
          Individual_MIRTData_Converted_AutoCombine[i,q]<-3} 
  }} 
}

#Now double check that none of the code 1 categories are under 5%. Except now several of the countries do not have any values for code 1, these cells need to be coded as NA, not 0. 
Counts <- data.frame()
Country_Breakdown<- aggregate(Individual_MIRTData_Converted_AutoCombine[,q], 
          by=list(Individual_MIRTData_Converted_AutoCombine$V2.x), 
          Likert_Count_Calc, simplify=FALSE)

for( i in 1:56){
 Count <- t(as.data.frame(Country_Breakdown$x[i])) 
 Counts<- as.data.frame(rbind(Counts, Count))
}
row.names(Counts) <- as.character(Country_Breakdown$Group.1)
country_sums <- as.data.frame(apply(Counts, 1, sum)) 
#in the count DF, the zeros in the 0 category are due to collasping or there were no respondants that selected this choice and should be changed to NA so that the model does not try to attempt to determine the threshold between 0 and 1. 
for (z in 1:56){ #56 countries
  if(Counts$r0[z] ==0){Counts$r0[z]<- NA}
}
for (z in 1:56){ #56 countries
 if(Counts$r1[z] ==0){Counts$r1[z] <- NA}
}
for (z in 1:56){ #56 countries
  if(Counts$r4[z] ==0){Counts$r4[z]<- NA}
}
#now lets create an updated DF with the collasped categories for certian countries.
Countries <- as.character(unique(Individual_MIRTData_Converted_AutoCombine$V2.x))
Spread_Comparison_Update2<-c()
Precents <- data.frame()

for(i in 1:56){
  Precent <- Counts[i,]/country_sums$`apply(Counts, 1, sum)`[i]
  Precents <- rbind(Precents, Precent)
}

Precents<-Precents[,c(1:5)]
Spread_Comparison_Update2 <- t(Precents*100)

# Checking that all Code 1 categories have more than 5%
CombineNone <- c()
Country <- NA

for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
  Spread_Comparison_Code5 <- Spread_Comparison_Update2[5,]
  if(!is.na(Spread_Comparison_Code5[i]) && Spread_Comparison_Code5[i]<= 5){
    Country <- names(Spread_Comparison_Code5[i])
  } else { Country <- NA
  }
   CombineNone<- cbind(CombineNone, Country)
}
 CombineNone<- na.omit(t(CombineNone))
 CombineNone<- as.character(CombineNone)
 CombineNone

  
filename = paste (q,"SpreadComparison_Weighted_Updated2.csv",sep="_")  
write.csv(Spread_Comparison_Update2, filename) 


} #start new question

#Save progress
Individual_MIRTData_Converted_AutoCombineStep5 <- Individual_MIRTData_Converted_AutoCombine
```

```{r Write.CSV Results from AutoCombine}
#Individual_MIRTData_Converted_AutoCombine <-read.csv("Individual_MIRTData_Converted_AutoCombine_Final.csv")
#Individual_MIRTData_Converted_AutoCombine <-Individual_MIRTData_Converted_AutoCombine[,c(2:216)]
```

#Nominal Items
The nominal items tyipically cannot be combined because they have no order. We will not look at the nominal items to understand if there is a large number of countries that answer consistently for a certain response. We could use the National Precentage Dataframe to create these dataframes. 
```{r Nominal Items Category Usage}
Nominal_Questions <- colnames(Individual_MIRTData_Converted_AutoCombine[,c(3:24)])
Nominal_LowCatPrecentage <- c()

for (p in Nominal_Questions){
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
      Code1_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Code1_Lessthan5percent<- cbind(Code1_Lessthan5percent, Country)
      }
      Code1_Lessthan5percent<- na.omit(t(Code1_Lessthan5percent))
      Code1_Lessthan5percent<- as.character(Code1_Lessthan5percent)
      Code1_Lessthan5percent_List <- Code1_Lessthan5percent
      Code1_Lessthan5percent<- paste(Code1_Lessthan5percent, sep=" ", collapse = ",") 
      
#instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
      Code2_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code2 <- Spread_Comparison[2,]
         if(Spread_Comparison_Code2[i]<= 5){
         Country <- names(Spread_Comparison_Code2[i])
         } else { Country <- NA
        }
      Code2_Lessthan5percent<- cbind(Code2_Lessthan5percent, Country)
      }
      Code2_Lessthan5percent<- na.omit(t(Code2_Lessthan5percent))
      Code2_Lessthan5percent<- as.character(Code2_Lessthan5percent)
      Code2_Lessthan5percent_List <- Code2_Lessthan5percent
      Code2_Lessthan5percent<- paste(Code2_Lessthan5percent, sep=" ", collapse = ",")  
      
#Code3 - instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
      Code3_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code3 <- Spread_Comparison[3,]
         if(Spread_Comparison_Code3[i]<= 5){
         Country <- names(Spread_Comparison_Code3[i])
         } else { Country <- NA
        }
      Code3_Lessthan5percent<- cbind(Code3_Lessthan5percent, Country)
      }
      Code3_Lessthan5percent<- na.omit(t(Code3_Lessthan5percent))
      Code3_Lessthan5percent<- as.character(Code3_Lessthan5percent)
      Code3_Lessthan5percent_List <- Code3_Lessthan5percent
      Code3_Lessthan5percent<- paste(Code3_Lessthan5percent, sep=" ", collapse = ",")  
  Code3_Lessthan5percent
  
#Code4 - instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
  if(nrow(Spread_Comparison) >=4){
      Code4_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code4 <- Spread_Comparison[4,]
         if(Spread_Comparison_Code4[i]<= 5){
         Country <- names(Spread_Comparison_Code4[i])
         } else { Country <- NA
        }
      Code4_Lessthan5percent<- cbind(Code4_Lessthan5percent, Country)
      }
      Code4_Lessthan5percent<- na.omit(t(Code4_Lessthan5percent))
      Code4_Lessthan5percent<- as.character(Code4_Lessthan5percent)
      Code4_Lessthan5percent_List <- Code4_Lessthan5percent
      Code4_Lessthan5percent<- paste(Code4_Lessthan5percent, sep=" ", collapse = ",")  
  Code4_Lessthan5percent 
  }else{Code4_Lessthan5percent=NA}
#Code5 - instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
  if(nrow(Spread_Comparison) >=5){
      Code5_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code5 <- Spread_Comparison[5,]
         if(Spread_Comparison_Code5[i]<= 5){
         Country <- names(Spread_Comparison_Code5[i])
         } else { Country <- NA
        }
      Code5_Lessthan5percent<- cbind(Code5_Lessthan5percent, Country)
      }
      Code5_Lessthan5percent<- na.omit(t(Code5_Lessthan5percent))
      Code5_Lessthan5percent<- as.character(Code5_Lessthan5percent)
      Code5_Lessthan5percent_List <- Code5_Lessthan5percent
      Code5_Lessthan5percent<- paste(Code5_Lessthan5percent, sep=" ", collapse = ",")  
  Code5_Lessthan5percent} else{Code5_Lessthan5percent=NA}
  
item <- paste(p,"LowCatPrecent",sep="_")
item<- cbind(Code1_Lessthan5percent,Code2_Lessthan5percent,Code3_Lessthan5percent, 
             Code4_Lessthan5percent, Code5_Lessthan5percent)
Nominal_LowCatPrecentage <- rbind(Nominal_LowCatPrecentage, item)
}

rownames(Nominal_LowCatPrecentage) <- Nominal_Questions
write.csv(Nominal_LowCatPrecentage, "Nominal_LowCatPrecentage.csv")
```

#Adjustment of Nominal Questions
Looking at some of the questions there are can be combined due to similar ideas. We are going to combine categories across all countries for the nominal questions since we are no longer just reducing the spread of a particular item.
```{r Adjustment of Nominal Questions}
#For V25-V35, we will combine active and inactive member categories to just be "members" coded as 1. This also changes the questions from a nominal question to a binary question. 
AutoCombineto1=colnames(Individual_MIRTData_Converted_AutoCombine[,c(3:13)])

for (p in AutoCombineto1){
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)

z=nrow(Individual_MIRTData_Converted_AutoCombine)
i=1
  for(i in 1:z){#this loops through ALL the responses
    if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
     Individual_MIRTData_Converted_AutoCombine[i,p]==2){
     Individual_MIRTData_Converted_AutoCombine[i,p]<-1} 
          } 
}


#For  questions V81, V150, and V151 there were "other" categoreies that were rarley used. We will recode those values to NA so that the IRT model does not have to estimate the parameters. These questions also become binary. 
RemoveCategories=c("V81","V150","V151")

for (p in RemoveCategories){
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)

z=nrow(Individual_MIRTData_Converted_AutoCombine)
i=1
  for(i in 1:z){#this loops through ALL the responses
    if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
     Individual_MIRTData_Converted_AutoCombine[i,p]==3){
     Individual_MIRTData_Converted_AutoCombine[i,p]<-NA}
    else if(!is.na(Individual_MIRTData_Converted_AutoCombine[i,p]) &&
     Individual_MIRTData_Converted_AutoCombine[i,p]==4){
     Individual_MIRTData_Converted_AutoCombine[i,p]<-NA}
          } 
        }
```

#Binary Items
```{r Binary Items Category Usage}
Binary_Questions <- colnames(Individual_MIRTData_Converted_AutoCombine[,c(25:60)])
Binary_LowCatPrecentage <- c()

for (p in Binary_Questions){
  Weighted_Spread_Comparison<- Weighted_Precentages [, grep(p, colnames(Weighted_Precentages))]
  rownames(Weighted_Spread_Comparison) <-Weighted_Precentages$X
  Spread_Comparison <- t(Weighted_Spread_Comparison)
  filename=paste(p,"SpreadComparison_Weighted.csv",sep="")
  write.csv(Spread_Comparison, filename)
  
  #instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
      Code1_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code1 <- Spread_Comparison[1,]
         if(Spread_Comparison_Code1[i]<= 5){
         Country <- names(Spread_Comparison_Code1[i])
         } else { Country <- NA
        }
      Code1_Lessthan5percent<- cbind(Code1_Lessthan5percent, Country)
      }
      Code1_Lessthan5percent<- na.omit(t(Code1_Lessthan5percent))
      Code1_Lessthan5percent<- as.character(Code1_Lessthan5percent)
      Code1_Lessthan5percent_List <- Code1_Lessthan5percent
      Code1_Lessthan5percent<- paste(Code1_Lessthan5percent, sep=" ", collapse = ",") 
      
#instead of combining categories, we just want to know which countries have less than 5% in which categories within a particular item.
      Code2_Lessthan5percent <- c()
      Country <- NA
      for(i in 1:56){#need to loop through row 1 of spread_comparison dataframe
         Spread_Comparison_Code2 <- Spread_Comparison[2,]
         if(Spread_Comparison_Code2[i]<= 5){
         Country <- names(Spread_Comparison_Code2[i])
         } else { Country <- NA
        }
      Code2_Lessthan5percent<- cbind(Code2_Lessthan5percent, Country)
      }
      Code2_Lessthan5percent<- na.omit(t(Code2_Lessthan5percent))
      Code2_Lessthan5percent<- as.character(Code2_Lessthan5percent)
      Code2_Lessthan5percent_List <- Code2_Lessthan5percent
      Code2_Lessthan5percent<- paste(Code2_Lessthan5percent, sep=" ", collapse = ",")  
      
      item <- paste(p,"LowCatPrecent",sep="_")
      item<- cbind(Code1_Lessthan5percent,Code2_Lessthan5percent)
      Binary_LowCatPrecentage <- rbind(Binary_LowCatPrecentage, item)
    }

rownames( Binary_LowCatPrecentage) <- Binary_Questions 
write.csv( Binary_LowCatPrecentage, "Binary_LowCatPrecentage.csv")
```
Questions V243,V244,V245,V246 are related to nationality and citizenship and are therefore more related to sociodemographics rather than values and should also be removed. 

```{r Write Results from AutoCombine}
Individual_MIRTData_Converted_AutoCombine_209 <-Individual_MIRTData_Converted_AutoCombine[,-which(names(Individual_MIRTData_Converted_AutoCombine)
                                              %in%c("V243","V244","V245","V246"))]

#write.csv(Individual_MIRTData_Converted_AutoCombine_209, "Individual_MIRTData_Converted_AutoCombine_NBMod.csv")
Individual_MIRTData_Converted_AutoCombine_209 <- read.csv("Individual_MIRTData_Converted_AutoCombine_NBMod.csv")
Individual_MIRTData_Converted_AutoCombine_209 <- Individual_MIRTData_Converted_AutoCombine_209[,c(2:212)]

colnames(Individual_MIRTData_Converted_AutoCombine_209)
```

#Ordered Questions 
Second collaspe of categories. There are several ordered questions where they could be collasped into less categories in a more unique way that the Likert scale. For example questions V70 to V79 ask a series of questions about desciptions of the respondant. There are 6 categories options (very much like me, like me, somewhat like me, a little like me, not like me, not at all like me). We have so far combined the edges into each other however, we could recode the questions to only have 3 categories (like me, some like me, not like me). To do this, we will recode 1&2 to 1, 3&4 to 2, and 5&6 to 3. 
```{r LikeMe Questions}
LikeMeQuestions <- colnames(Individual_MIRTData[,c(72:81)])
for(m in LikeMeQuestions){
  for(i in 1:85264){ #this loops through ALL the responses
  if(!is.na(Individual_MIRTData_Converted_AutoCombine_209[i,m])) {
    if(Individual_MIRTData_Converted_AutoCombine_209[i,m]== 1 ||Individual_MIRTData_Converted_AutoCombine_209[i,m]==  2)
                {Individual_MIRTData_Converted_AutoCombine_209[i,m] <- 1}  #converts all 1s & 2s into 1s
    else if(Individual_MIRTData_Converted_AutoCombine_209[i,m]== 3 ||Individual_MIRTData_Converted_AutoCombine_209[i,m]==  4)
                {Individual_MIRTData_Converted_AutoCombine_209[i,m] <- 2}  #converts all 3s &4s into 2s
    else if(Individual_MIRTData_Converted_AutoCombine_209[i,m]== 5 ||Individual_MIRTData_Converted_AutoCombine_209[i,m]==  6)
            {Individual_MIRTData_Converted_AutoCombine_209[i,m] <- 3}  #converts all 5s &6s into 3s
    }
   }
}

#Check
table(Individual_MIRTData_Converted_AutoCombine_209$V211)


#Another question is V211 - Which asks How proud you are to be from your country? We need to remove the response that is I'm not...because it was not read out, it was only marked if volunteered. 
Nationalism <- "V211"
for(m in Nationalism){
  for(i in 1:85264){ #this loops through ALL the responses
  if(!is.na(Individual_MIRTData_Converted_AutoCombine_209[i,m])) {
    if     (Individual_MIRTData_Converted_AutoCombine_209[i,m]== 5 )
                {Individual_MIRTData_Converted_AutoCombine_209[i,m] <- NA}  #converts all 5s into NAs
        }
   }
}

#write.csv(Individual_MIRTData_Converted_AutoCombine_209, "Individual_MIRTData_Converted_AutoCombine_NBOMod.csv")


#The remaining questions have responses that can have more set of collasping without changing the meaning for those particular countries. For questions V146, V145, V217-V224, categories can be combined once more. 

```

#Final Data Frame
```{r Remove Non-choice Questions}
#Remove questions which are not related to an active choice by a single person - i.e. completely dependent on the environment in which they are located. 

Individual_MIRTData_198 <-Individual_MIRTData[,-which(names(Individual_MIRTData)
                                              %in%c("V171","V172","V173","V174","V175","V179","V180","V188"
                                                    ,"V189","V190","V191"))]

#write.csv(Individual_MIRTData_198,"Individual_MIRTData_NBO198.csv")

Final_Variables <- colnames(Individual_MIRTData_198)
```

#Model Setup 
The variables and item types must be manually changed if the variables are changed. If the variables are changed make sure to update the dataframe that is being analyzed in the multipleGroup function. The number of factors can be changed by changing the value of model. 
```{r MIRT Setup, eval=FALSE}
Individual_MIRTData <- read.csv("Individual_MIRTData_NBO198.csv")
Individual_MIRTData <- Individual_MIRTData[,c(3:202)]

library(mirt)
library(parallel)
library(plyr)

Individual_MIRTData_test <- Individual_MIRTData

model=5

itemT <- rep('graded', 198) #Ordered 
itemT[1:11] <- '2PL' #Categorical, but reduced to binary
itemT[12:22] <- 'nominal' 
itemT[19] <- '2PL' #Categorical, but reduced to binary
itemT[21] <- '2PL' #Categorical, but reduced to binary
itemT[22] <- '2PL' #Categorical, but reduced to binary
itemT[23:52] <- '2PL' #Binary

#load("Large_NBO_198Q56C_5F_EM.Rdata")
load("StartingParameters_NBO_198Q56C_5F_EM.Rdata")

Grouped_MIRT <- multipleGroup(Individual_MIRTData_test[,c(3:200)], 
                                               model = model,
                                               group = as.character(Individual_MIRTData_test$V2.x),
                                               rotate = "none",
                                               invariance = c("slopes","intercepts","free_means"),
                                               itemtype=itemT,
                                               method = "EM", technical=list(NCYCLES=5), 
                                               pars=Parameters,
		                                           survey.weights = Individual_MIRTData_test$V258.x)

Grouped_MIRT@Fit$AIC
Grouped_MIRT@Fit$BIC

#save model
save(Grouped_MIRT, file="Model_NBO_198Q56C_5F_EM_Short_noLarge.Rdata")

#summary(Grouped_MIRT, rotate= "none")
#summary(Grouped_MIRT, rotate="oblimin")
Varimax <- summary(Grouped_MIRT, rotate="varimax")
```

#Load Model
This model was created using high power computing 
```{r Load Model from HPC}
library(mirt)
library(parallel)
library(plyr)

#the modem item is saved as Grouped_MIRT
load("C:/Users/laall/Google Drive (laalliso@uw.edu)/02 General Exam/FormatCode/Model_NBO_198Q56C_5F_EM_Short_noLarge.Rdata")

Individual_MIRTData <- read.csv("Individual_MIRTData_NBO198.csv")
Individual_MIRTData <- Individual_MIRTData[,c(3:202)]
```

#Parameters
##Extract the Coefficients 
When the slope and intercept are held equal, every country should have exactly equal parameters. Therefore, you should be able to randomly choose two countries to make into csv files and they should be equivalent. 
```{r Coefficients}
Coef_Grouped_MIRT_Model_All_Countries <- coef(Grouped_MIRT_CFA)
names(Coef_Grouped_MIRT_Model_All_Countries)

#in order to see the results from hyak, we need to export the results to a csv file. If you export it as is or even just a single country. It is a sinlge row with all the paramters going across. We need to be simplify this so that each variable is a row and the columns are labelled with the parameters. Normally you can say simplify equals true for a single country in the coef function. Each country is listed by it's country code
library(plyr, quietly = TRUE)

#Need to store the coef dataframe under country name
Coef_Names <- paste("Coef",unique(Reduced_DF_5F3_NA$Individual_MIRTData.V2.x), sep = "_")
LatentMV_Names <- paste("Latent_MeanVar",unique(Reduced_DF_2F_NA$V2), sep = "_")
Latent_MV_All <- c()

i=1
j=1
for(i in 1:42){#loops through the countries
  Country_Coef<- Coef_Grouped_MIRT_Model_All_Countries[[i]] #focuses on one country
  #this data frame will be used to store the coefficients
  Variables_Coef_All <- c()
  for(j in 1:90){#loop through all variables
    Variables_Coef <- as.data.frame(do.call(rbind.data.frame, Country_Coef[j]))
    Variables_Coef_All <- rbind.fill(Variables_Coef_All, Variables_Coef)
    j=j+1
    }
    Latent_MeanVar <- as.data.frame(do.call(rbind.data.frame, Country_Coef[199]))
    Latent_MV_All <- rbind(Latent_MV_All,Latent_MeanVar)
    
  rownames(Variables_Coef_All)<- names(Country_Coef[c(1:90)])
  assign(Coef_Names[i], as.data.frame(Variables_Coef_All))
  #assign(LatentMV_Names[i], as.data.frame(Latent_MeanVar))
  i=i+1
}
rownames(Latent_MV_All)<-LatentMV_Names
#Order of the countries
unique(Individual_MIRTData$V2.x)
```
This section will write the coefficients to seperate csv files for each country. However, since we specified that the countries should have equal coefficients (both slope and intercepts) all the files should show the exact same values.
```{r Coefficient Files}
#Rich Countries
write.csv(Coef_36, "Coef_36_Austrailia.csv") 
write.csv(Coef_276, "Coef_276_Germany.csv") 
write.csv(Coef_392, "Coef_392_Japan.csv")
write.csv(Coef_724, "Coef_724_Spain.csv")
write.csv(Coef_752, "Coef_752_Sweden.csv")
write.csv(Coef_840, "Coef_840_UnitedStates.csv")

#Remaining countries
write.csv(Coef_12, "Coef_12_Algeria.csv")
write.csv(Coef_31, "Coef_31_Azerbaijan.csv")
write.csv(Coef_32, "Coef_32_Argentina.csv")
write.csv(Coef_51, "Coef_51_Armenia.csv")
write.csv(Coef_76, "Coef_76_Brazil.csv")
write.csv(Coef_112,"Coef_112_Belarus.csv")
write.csv(Coef_152,"Coef_152_Chile.csv")
write.csv(Coef_156, "Coef_156_China.csv")
write.csv(Coef_158, "Coef_158_Taiwan.csv")
write.csv(Coef_170, "Coef_170_Colombia.csv")
write.csv(Coef_196, "Coef_196_Cyprus.csv")
write.csv(Coef_218, "Coef_218_Equador.csv")
write.csv(Coef_233, "Coef_233_Estonia.csv")
write.csv(Coef_268, "Coef_268_Georgia.csv")
write.csv(Coef_275, "Coef_275_Palestine.csv")
write.csv(Coef_288, "Coef_288_Ghana.csv")
write.csv(Coef_344, "Coef_344_HongKong.csv")
write.csv(Coef_356, "Coef_356_India.csv")
write.csv(Coef_368, "Coef_368_Iraq.csv")
write.csv(Coef_398, "Coef_398_Kazakhstan.csv")
write.csv(Coef_400, "Coef_400_Jordan.csv")
write.csv(Coef_410, "Coef_410_SouthKorea.csv")
write.csv(Coef_417, "Coef_417_Kyrgyzstan.csv")
write.csv(Coef_422, "Coef_422_Lebanon.csv")
write.csv(Coef_434, "Coef_434_Libya.csv")
write.csv(Coef_458, "Coef_458_Malaysia.csv")
write.csv(Coef_484, "Coef_484_Mexico.csv")
write.csv(Coef_504, "Coef_504_Morocco.csv")
write.csv(Coef_528, "Coef_528_Netherlands.csv")
write.csv(Coef_554, "Coef_554_NewZealand.csv")
write.csv(Coef_566, "Coef_566_Nigeria.csv")
write.csv(Coef_586, "Coef_586_Pakistan.csv")
write.csv(Coef_604, "Coef_604_Peru.csv")
write.csv(Coef_608, "Coef_608_Phillipines.csv")
write.csv(Coef_616, "Coef_616_Poland.csv")
write.csv(Coef_642, "Coef_642_Romania.csv")
write.csv(Coef_643, "Coef_643_Russia.csv")
write.csv(Coef_646, "Coef_646_Rwanda.csv")
write.csv(Coef_702, "Coef_702_Singapore.csv")
write.csv(Coef_705, "Coef_705_Slovenia.csv")
write.csv(Coef_710, "Coef_710_SouthAfrica.csv")
write.csv(Coef_716, "Coef_716_Zimbabwe.csv")
write.csv(Coef_764, "Coef_764_Thailand.csv")
write.csv(Coef_780, "Coef_780_Trinidad.csv")
write.csv(Coef_788, "Coef_788_Tunisia.csv")
write.csv(Coef_792, "Coef_792_Turkey.csv")
write.csv(Coef_804, "Coef_804_Ukraine.csv")
write.csv(Coef_858, "Coef_858_Uruguay.csv")
write.csv(Coef_860, "Coef_860_Uzbekistan.csv")
write.csv(Coef_887, "Coef_887_Yemen.csv")
```

##Factors Loading Paramters
Since an item response function in not how the factor analyses are traditionally done, the coefficients are tranformed into the factor loadings that are typically interpreted. If the model allowed the variance to differ between countries, the countries will have variation in the magintude of the factor loadings; however, the order and direction of variables effect on the factor will remain the same. As is common in factor analysis, rotations are applied in order to gain a more clear prespective of the factors. In this code, no rotation, varimax rotation, and oblimin rotation are analyzed. 

###No Rotate
```{r NoRotate Loadings & Communalities, eval=FALSE}
#No Rotation in factor loadings 
Grouped_MIRT_Model_All_Countries_Summary <- summary(Grouped_MIRT_Model_All_Countries, rotate="none")

#Need to store the coef dataframe under country name
Summary_Names <- paste("Summary_NoRotate",unique(Individual_MIRTData$V2.x),sep = "_")
Communalities <- paste("Communalities_NoRotate",unique(Individual_MIRTData$V2.x),sep = "_")

i=1
for(i in 1:n){#loops through the countries
  Country_Loadings <-Grouped_MIRT_Model_All_Countries_Summary[[i]] #focuses on one country
  names(Country_Loadings)
  Country_Loadings_Values <- as.data.frame(Country_Loadings$rotF)
  Country_Communalitites <- as.data.frame(Country_Loadings$h2)
  assign(Summary_Names[i], Country_Loadings_Values)
  assign(Communalities[i], Country_Communalitites)
  i=i+1
}
```

```{r NoRotate Communality CSV files, eval=FALSE}
NoRotate_Communalities <-cbind(Communalities_NoRotate_36,  Communalities_NoRotate_276, 
                               Communalities_NoRotate_392, Communalities_NoRotate_724, 
                               Communalities_NoRotate_752, Communalities_NoRotate_840,
                               Communalities_NoRotate_12,  Communalities_NoRotate_31,  Communalities_NoRotate_32, 
                               Communalities_NoRotate_51,  Communalities_NoRotate_76,  Communalities_NoRotate_112,
                               Communalities_NoRotate_152, Communalities_NoRotate_156, Communalities_NoRotate_158, 
                               Communalities_NoRotate_170, Communalities_NoRotate_196, Communalities_NoRotate_218,
                               Communalities_NoRotate_233, Communalities_NoRotate_268, Communalities_NoRotate_275,
                               Communalities_NoRotate_288, Communalities_NoRotate_344, Communalities_NoRotate_356,
                               Communalities_NoRotate_368, Communalities_NoRotate_398, Communalities_NoRotate_400,
                               Communalities_NoRotate_410, Communalities_NoRotate_417, Communalities_NoRotate_422,
                               Communalities_NoRotate_434, Communalities_NoRotate_458, Communalities_NoRotate_484,
                               Communalities_NoRotate_504, Communalities_NoRotate_528, Communalities_NoRotate_554,
                               Communalities_NoRotate_566, Communalities_NoRotate_586, Communalities_NoRotate_604, 
                               Communalities_NoRotate_608, Communalities_NoRotate_616, Communalities_NoRotate_642,
                               Communalities_NoRotate_643, Communalities_NoRotate_646, Communalities_NoRotate_702,
                               Communalities_NoRotate_705, Communalities_NoRotate_710, Communalities_NoRotate_716, 
                               Communalities_NoRotate_764, Communalities_NoRotate_780, Communalities_NoRotate_788,
                               Communalities_NoRotate_792, Communalities_NoRotate_804, Communalities_NoRotate_858,
                               Communalities_NoRotate_860, Communalities_NoRotate_887)

 CountryCodes_Titles<- c("36_Austrailia", "276_Germany", "392_Japan", "724_Spain", 
                         "752_Sweden", "840_US","12_Algeria","31_Azerbaijan",
                         "32_Argentina","51_Armenia","76_Brazil","112_Belarus",
                         "152_Chile","156_China","158_Taiwan","170_Colombia",
                         "196_Cyprus","218_Equador","233_Estonia","268_Georgia",
                         "275_Palestine","288_Ghana","344_HongKong","356_India",
                         "368_Iraq","398_Kazakhstan","400_Jordan","410_SouthKorea",
                         "417_Kyrgyzstan","422_Lebanon","434_Libya","458_Malaysia",
                         "484_Mexico","504_Morocco","528_Netherlands","554_NewZealand",
                         "566_Nigeria","586_Pakistan","604_Peru","608_Phillipines",
                         "616_Poland","642_Romania","643_Russia","646_Rwanda",
                         "702_Singapore","705_Slovenia","710_SouthAfrica","716_Zimbabwe",
                         "764_Thailand","780_Trinidad","788_Tunisia","792_Turkey",
                         "804_Ukraine","858_Uruguay","860_Uzbekistan","887_Yemen")
 
colnames(NoRotate_Communalities) <- CountryCodes_Titles

#All countries as one csv
write.csv(NoRotate_Communalities, "Communalities_NoRotate.csv")

#Wealthy Countries
write.csv(Communalities_NoRotate_36, "Communalities_NoRotate_36_Austrailia.csv")
write.csv(Communalities_NoRotate_276, "Communalities_NoRotate_276_Germany.csv")
write.csv(Communalities_NoRotate_392, "Communalities_NoRotate_392_Japan.csv")
write.csv(Communalities_NoRotate_724, "Communalities_NoRotate_724_Spain.csv")
write.csv(Communalities_NoRotate_752, "Communalities_NoRotate_752_Sweden.csv")
write.csv(Communalities_NoRotate_840, "Communalities_NoRotate_840_UnitedStates.csv")

#Remaining Countries
write.csv(Communalities_NoRotate_12, "Communalities_NoRotate_12_Algeria.csv")
write.csv(Communalities_NoRotate_31, "Communalities_NoRotate_31_Azerbaijan.csv")
write.csv(Communalities_NoRotate_32, "Communalities_NoRotate_32_Argentina.csv")
write.csv(Communalities_NoRotate_51, "Communalities_NoRotate_51_Armenia.csv")
write.csv(Communalities_NoRotate_76, "Communalities_NoRotate_76_Brazil.csv")
write.csv(Communalities_NoRotate_112,"Communalities_NoRotate_112_Belarus.csv")
write.csv(Communalities_NoRotate_152,"Communalities_NoRotate_152_Chile.csv")
write.csv(Communalities_NoRotate_156, "Communalities_NoRotate_156_China.csv")
write.csv(Communalities_NoRotate_158, "Communalities_NoRotate_158_Taiwan.csv")
write.csv(Communalities_NoRotate_170, "Communalities_NoRotate_170_Colombia.csv")
write.csv(Communalities_NoRotate_196, "Communalities_NoRotate_196_Cyprus.csv")
write.csv(Communalities_NoRotate_218, "Communalities_NoRotate_218_Equador.csv")
write.csv(Communalities_NoRotate_233, "Communalities_NoRotate_233_Estonia.csv")
write.csv(Communalities_NoRotate_268, "Communalities_NoRotate_268_Georgia.csv")
write.csv(Communalities_NoRotate_275, "Communalities_NoRotate_275_Palestine.csv")
write.csv(Communalities_NoRotate_288, "Communalities_NoRotate_288_Ghana.csv")
write.csv(Communalities_NoRotate_344, "Communalities_NoRotate_344_HongKong.csv")
write.csv(Communalities_NoRotate_356, "Communalities_NoRotate_356_India.csv")
write.csv(Communalities_NoRotate_368, "Communalities_NoRotate_368_Iraq.csv")
write.csv(Communalities_NoRotate_398, "Communalities_NoRotate_398_Kazakhstan.csv")
write.csv(Communalities_NoRotate_400, "Communalities_NoRotate_400_Jordan.csv")
write.csv(Communalities_NoRotate_410, "Communalities_NoRotate_410_SouthKorea.csv")
write.csv(Communalities_NoRotate_417, "Communalities_NoRotate_417_Kyrgyzstan.csv")
write.csv(Communalities_NoRotate_422, "Communalities_NoRotate_422_Lebanon.csv")
write.csv(Communalities_NoRotate_434, "Communalities_NoRotate_434_Libya.csv")
write.csv(Communalities_NoRotate_458, "Communalities_NoRotate_458_Malaysia.csv")
write.csv(Communalities_NoRotate_484, "Communalities_NoRotate_484_Mexico.csv")
write.csv(Communalities_NoRotate_504, "Communalities_NoRotate_504_Morocco.csv")
write.csv(Communalities_NoRotate_528, "Communalities_NoRotate_528_Netherlands.csv")
write.csv(Communalities_NoRotate_554, "Communalities_NoRotate_554_NewZealand.csv")
write.csv(Communalities_NoRotate_566, "Communalities_NoRotate_566_Nigeria.csv")
write.csv(Communalities_NoRotate_586, "Communalities_NoRotate_586_Pakistan.csv")
write.csv(Communalities_NoRotate_604, "Communalities_NoRotate_604_Peru.csv")
write.csv(Communalities_NoRotate_608, "Communalities_NoRotate_608_Phillipines.csv")
write.csv(Communalities_NoRotate_616, "Communalities_NoRotate_616_Poland.csv")
write.csv(Communalities_NoRotate_642, "Communalities_NoRotate_642_Romania.csv")
write.csv(Communalities_NoRotate_643, "Communalities_NoRotate_643_Russia.csv")
write.csv(Communalities_NoRotate_646, "Communalities_NoRotate_646_Rwanda.csv")
write.csv(Communalities_NoRotate_702, "Communalities_NoRotate_702_Singapore.csv")
write.csv(Communalities_NoRotate_705, "Communalities_NoRotate_705_Slovenia.csv")
write.csv(Communalities_NoRotate_710, "Communalities_NoRotate_710_SouthAfrica.csv")
write.csv(Communalities_NoRotate_716, "Communalities_NoRotate_716_Zimbabwe.csv")
write.csv(Communalities_NoRotate_764, "Communalities_NoRotate_764_Thailand.csv")
write.csv(Communalities_NoRotate_780, "Communalities_NoRotate_780_Trinidad.csv")
write.csv(Communalities_NoRotate_788, "Communalities_NoRotate_788_Tunisia.csv")
write.csv(Communalities_NoRotate_792, "Communalities_NoRotate_792_Turkey.csv")
write.csv(Communalities_NoRotate_804, "Communalities_NoRotate_804_Ukraine.csv")
write.csv(Communalities_NoRotate_858, "Communalities_NoRotate_858_Uruguay.csv")
write.csv(Communalities_NoRotate_860, "Communalities_NoRotate_860_Uzbekistan.csv")
write.csv(Communalities_NoRotate_887, "Communalities_NoRotate_887_Yemen.csv")
```

If the variance was held to one across all groups the loadings will be exactly the same and there in no need to compare the loadings across countries instead look at the loadings for any random country and compare the different factors.
```{r NoRotate F1 Loadings CSV files, eval=FALSE}
#All 56 Countries
F1_NoRotate <-cbind(Summary_NoRotate_36$F1,  Summary_NoRotate_276$F1, Summary_NoRotate_392$F1,
                    Summary_NoRotate_724$F1, Summary_NoRotate_752$F1, Summary_NoRotate_840$F1,
                    Summary_NoRotate_12$F1,  Summary_NoRotate_31$F1,  Summary_NoRotate_32$F1, 
                    Summary_NoRotate_51$F1,  Summary_NoRotate_76$F1,  Summary_NoRotate_112$F1,
                    Summary_NoRotate_152$F1, Summary_NoRotate_156$F1, Summary_NoRotate_158$F1, 
                    Summary_NoRotate_170$F1, Summary_NoRotate_196$F1, Summary_NoRotate_218$F1,
                    Summary_NoRotate_233$F1, Summary_NoRotate_268$F1, Summary_NoRotate_275$F1,
                    Summary_NoRotate_288$F1, Summary_NoRotate_344$F1, Summary_NoRotate_356$F1,
                    Summary_NoRotate_368$F1, Summary_NoRotate_398$F1, Summary_NoRotate_400$F1,
                    Summary_NoRotate_410$F1, Summary_NoRotate_417$F1, Summary_NoRotate_422$F1,
                    Summary_NoRotate_434$F1, Summary_NoRotate_458$F1, Summary_NoRotate_484$F1,
                    Summary_NoRotate_504$F1, Summary_NoRotate_528$F1, Summary_NoRotate_554$F1,
                    Summary_NoRotate_566$F1, Summary_NoRotate_586$F1, Summary_NoRotate_604$F1, 
                    Summary_NoRotate_608$F1, Summary_NoRotate_616$F1, Summary_NoRotate_642$F1,
                    Summary_NoRotate_643$F1, Summary_NoRotate_646$F1, Summary_NoRotate_702$F1,
                    Summary_NoRotate_705$F1, Summary_NoRotate_710$F1, Summary_NoRotate_716$F1, 
                    Summary_NoRotate_764$F1, Summary_NoRotate_780$F1, Summary_NoRotate_788$F1,
                    Summary_NoRotate_792$F1, Summary_NoRotate_804$F1, Summary_NoRotate_858$F1,
                    Summary_NoRotate_860$F1, Summary_NoRotate_887$F1)

colnames(F1_NoRotate) <- CountryCodes_Titles
#All countries F1 Loadings
write.csv(F1_NoRotate, "F1_Loadings_NoRotate.csv")
```

```{r NoRotate F2 Loadings CSV files, eval=FALSE}
#All 56 Countries
F2_NoRotate <-cbind(Summary_NoRotate_36$F2,  Summary_NoRotate_276$F2, Summary_NoRotate_392$F2,
                    Summary_NoRotate_724$F2, Summary_NoRotate_752$F2, Summary_NoRotate_840$F2,
                    Summary_NoRotate_12$F2,  Summary_NoRotate_31$F2,  Summary_NoRotate_32$F2, 
                    Summary_NoRotate_51$F2,  Summary_NoRotate_76$F2,  Summary_NoRotate_112$F2,
                    Summary_NoRotate_152$F2, Summary_NoRotate_156$F2, Summary_NoRotate_158$F2, 
                    Summary_NoRotate_170$F2, Summary_NoRotate_196$F2, Summary_NoRotate_218$F2,
                    Summary_NoRotate_233$F2, Summary_NoRotate_268$F2, Summary_NoRotate_275$F2,
                    Summary_NoRotate_288$F2, Summary_NoRotate_344$F2, Summary_NoRotate_356$F2,
                    Summary_NoRotate_368$F2, Summary_NoRotate_398$F2, Summary_NoRotate_400$F2,
                    Summary_NoRotate_410$F2, Summary_NoRotate_417$F2, Summary_NoRotate_422$F2,
                    Summary_NoRotate_434$F2, Summary_NoRotate_458$F2, Summary_NoRotate_484$F2,
                    Summary_NoRotate_504$F2, Summary_NoRotate_528$F2, Summary_NoRotate_554$F2,
                    Summary_NoRotate_566$F2, Summary_NoRotate_586$F2, Summary_NoRotate_604$F2, 
                    Summary_NoRotate_608$F2, Summary_NoRotate_616$F2, Summary_NoRotate_642$F2,
                    Summary_NoRotate_643$F2, Summary_NoRotate_646$F2, Summary_NoRotate_702$F2,
                    Summary_NoRotate_705$F2, Summary_NoRotate_710$F2, Summary_NoRotate_716$F2, 
                    Summary_NoRotate_764$F2, Summary_NoRotate_780$F2, Summary_NoRotate_788$F2,
                    Summary_NoRotate_792$F2, Summary_NoRotate_804$F2, Summary_NoRotate_858$F2,
                    Summary_NoRotate_860$F2, Summary_NoRotate_887$F2)

colnames(F2_NoRotate) <- CountryCodes_Titles
write.csv(F2_NoRotate, "F2_Loadings_NoRotate.csv")
```

```{r NoRotate F3 Loadings CSV files, eval=FALSE}
#All 56 Countries
F3_NoRotate <-cbind(Summary_NoRotate_36$F3,  Summary_NoRotate_276$F3, Summary_NoRotate_392$F3,
                    Summary_NoRotate_724$F3, Summary_NoRotate_752$F3, Summary_NoRotate_840$F3,
                    Summary_NoRotate_12$F3,  Summary_NoRotate_31$F3,  Summary_NoRotate_32$F3, 
                    Summary_NoRotate_51$F3,  Summary_NoRotate_76$F3,  Summary_NoRotate_112$F3,
                    Summary_NoRotate_152$F3, Summary_NoRotate_156$F3, Summary_NoRotate_158$F3, 
                    Summary_NoRotate_170$F3, Summary_NoRotate_196$F3, Summary_NoRotate_218$F3,
                    Summary_NoRotate_233$F3, Summary_NoRotate_268$F3, Summary_NoRotate_275$F3,
                    Summary_NoRotate_288$F3, Summary_NoRotate_344$F3, Summary_NoRotate_356$F3,
                    Summary_NoRotate_368$F3, Summary_NoRotate_398$F3, Summary_NoRotate_400$F3,
                    Summary_NoRotate_410$F3, Summary_NoRotate_417$F3, Summary_NoRotate_422$F3,
                    Summary_NoRotate_434$F3, Summary_NoRotate_458$F3, Summary_NoRotate_484$F3,
                    Summary_NoRotate_504$F3, Summary_NoRotate_528$F3, Summary_NoRotate_554$F3,
                    Summary_NoRotate_566$F3, Summary_NoRotate_586$F3, Summary_NoRotate_604$F3, 
                    Summary_NoRotate_608$F3, Summary_NoRotate_616$F3, Summary_NoRotate_642$F3,
                    Summary_NoRotate_643$F3, Summary_NoRotate_646$F3, Summary_NoRotate_702$F3,
                    Summary_NoRotate_705$F3, Summary_NoRotate_710$F3, Summary_NoRotate_716$F3, 
                    Summary_NoRotate_764$F3, Summary_NoRotate_780$F3, Summary_NoRotate_788$F3,
                    Summary_NoRotate_792$F3, Summary_NoRotate_804$F3, Summary_NoRotate_858$F3,
                    Summary_NoRotate_860$F3, Summary_NoRotate_887$F3)

colnames(F3_NoRotate) <- CountryCodes_Titles
write.csv(F3_NoRotate, "F3_Loadings_NoRotate.csv")
```

```{r NoRotate F4 Loadings CSV files, eval=FALSE}
#All 56 Countries
F4_NoRotate <-cbind(Summary_NoRotate_36$F4,  Summary_NoRotate_276$F4, Summary_NoRotate_392$F4,
                    Summary_NoRotate_724$F4, Summary_NoRotate_752$F4, Summary_NoRotate_840$F4,
                    Summary_NoRotate_12$F4,  Summary_NoRotate_31$F4,  Summary_NoRotate_32$F4, 
                    Summary_NoRotate_51$F4,  Summary_NoRotate_76$F4,  Summary_NoRotate_112$F4,
                    Summary_NoRotate_152$F4, Summary_NoRotate_156$F4, Summary_NoRotate_158$F4, 
                    Summary_NoRotate_170$F4, Summary_NoRotate_196$F4, Summary_NoRotate_218$F4,
                    Summary_NoRotate_233$F4, Summary_NoRotate_268$F4, Summary_NoRotate_275$F4,
                    Summary_NoRotate_288$F4, Summary_NoRotate_344$F4, Summary_NoRotate_356$F4,
                    Summary_NoRotate_368$F4, Summary_NoRotate_398$F4, Summary_NoRotate_400$F4,
                    Summary_NoRotate_410$F4, Summary_NoRotate_417$F4, Summary_NoRotate_422$F4,
                    Summary_NoRotate_434$F4, Summary_NoRotate_458$F4, Summary_NoRotate_484$F4,
                    Summary_NoRotate_504$F4, Summary_NoRotate_528$F4, Summary_NoRotate_554$F4,
                    Summary_NoRotate_566$F4, Summary_NoRotate_586$F4, Summary_NoRotate_604$F4, 
                    Summary_NoRotate_608$F4, Summary_NoRotate_616$F4, Summary_NoRotate_642$F4,
                    Summary_NoRotate_643$F4, Summary_NoRotate_646$F4, Summary_NoRotate_702$F4,
                    Summary_NoRotate_705$F4, Summary_NoRotate_710$F4, Summary_NoRotate_716$F4, 
                    Summary_NoRotate_764$F4, Summary_NoRotate_780$F4, Summary_NoRotate_788$F4,
                    Summary_NoRotate_792$F4, Summary_NoRotate_804$F4, Summary_NoRotate_858$F4,
                    Summary_NoRotate_860$F4, Summary_NoRotate_887$F4)

colnames(F4_NoRotate) <- CountryCodes_Titles
write.csv(F4_NoRotate, "F4_Loadings_NoRotate.csv")
```

```{r All Factor Loadings by Country NoRotate csv files, eval=FALSE}
#All the loadings should be the same if the variation was held to one
write.csv(Summary_NoRotate_36, "Summary_NoRotate_36_Austrailia.csv")
write.csv(Summary_NoRotate_276, "Summary_NoRotate_276_Germany.csv")
write.csv(Summary_NoRotate_392, "Summary_NoRotate_392_Japan.csv")
write.csv(Summary_NoRotate_724, "Summary_NoRotate_724_Spain.csv")
write.csv(Summary_NoRotate_752, "Summary_NoRotate_752_Sweden.csv")
write.csv(Summary_NoRotate_840, "Summary_NoRotate_840_UnitedStates.csv")

write.csv(Summary_NoRotate_12, "Summary_NoRotate_12_Algeria.csv")
write.csv(Summary_NoRotate_31, "Summary_NoRotate_31_Azerbaijan.csv")
write.csv(Summary_NoRotate_32, "Summary_NoRotate_32_Argentina.csv")
write.csv(Summary_NoRotate_51, "Summary_NoRotate_51_Armenia.csv")
write.csv(Summary_NoRotate_76, "Summary_NoRotate_76_Brazil.csv")
write.csv(Summary_NoRotate_112,"Summary_NoRotate_112_Belarus.csv")
write.csv(Summary_NoRotate_152,"Summary_NoRotate_152_Chile.csv")
write.csv(Summary_NoRotate_156, "Summary_NoRotate_156_China.csv")
write.csv(Summary_NoRotate_158, "Summary_NoRotate_158_Taiwan.csv")
write.csv(Summary_NoRotate_170, "Summary_NoRotate_170_Colombia.csv")
write.csv(Summary_NoRotate_196, "Summary_NoRotate_196_Cyprus.csv")
write.csv(Summary_NoRotate_218, "Summary_NoRotate_218_Equador.csv")
write.csv(Summary_NoRotate_233, "Summary_NoRotate_233_Estonia.csv")
write.csv(Summary_NoRotate_268, "Summary_NoRotate_268_Georgia.csv")
write.csv(Summary_NoRotate_275, "Summary_NoRotate_275_Palestine.csv")
write.csv(Summary_NoRotate_288, "Summary_NoRotate_288_Ghana.csv")
write.csv(Summary_NoRotate_344, "Summary_NoRotate_344_HongKong.csv")
write.csv(Summary_NoRotate_356, "Summary_NoRotate_356_India.csv")
write.csv(Summary_NoRotate_368, "Summary_NoRotate_368_Iraq.csv")
write.csv(Summary_NoRotate_398, "Summary_NoRotate_398_Kazakhstan.csv")
write.csv(Summary_NoRotate_400, "Summary_NoRotate_400_Jordan.csv")
write.csv(Summary_NoRotate_410, "Summary_NoRotate_410_SouthKorea.csv")
write.csv(Summary_NoRotate_417, "Summary_NoRotate_417_Kyrgyzstan.csv")
write.csv(Summary_NoRotate_422, "Summary_NoRotate_422_Lebanon.csv")
write.csv(Summary_NoRotate_434, "Summary_NoRotate_434_Libya.csv")
write.csv(Summary_NoRotate_458, "Summary_NoRotate_458_Malaysia.csv")
write.csv(Summary_NoRotate_484, "Summary_NoRotate_484_Mexico.csv")
write.csv(Summary_NoRotate_504, "Summary_NoRotate_504_Morocco.csv")
write.csv(Summary_NoRotate_528, "Summary_NoRotate_528_Netherlands.csv")
write.csv(Summary_NoRotate_554, "Summary_NoRotate_554_NewZealand.csv")
write.csv(Summary_NoRotate_566, "Summary_NoRotate_566_Nigeria.csv")
write.csv(Summary_NoRotate_586, "Summary_NoRotate_586_Pakistan.csv")
write.csv(Summary_NoRotate_604, "Summary_NoRotate_604_Peru.csv")
write.csv(Summary_NoRotate_608, "Summary_NoRotate_608_Phillipines.csv")
write.csv(Summary_NoRotate_616, "Summary_NoRotate_616_Poland.csv")
write.csv(Summary_NoRotate_642, "Summary_NoRotate_642_Romania.csv")
write.csv(Summary_NoRotate_643, "Summary_NoRotate_643_Russia.csv")
write.csv(Summary_NoRotate_646, "Summary_NoRotate_646_Rwanda.csv")
write.csv(Summary_NoRotate_702, "Summary_NoRotate_702_Singapore.csv")
write.csv(Summary_NoRotate_705, "Summary_NoRotate_705_Slovenia.csv")
write.csv(Summary_NoRotate_710, "Summary_NoRotate_710_SouthAfrica.csv")
write.csv(Summary_NoRotate_716, "Summary_NoRotate_716_Zimbabwe.csv")
write.csv(Summary_NoRotate_764, "Summary_NoRotate_764_Thailand.csv")
write.csv(Summary_NoRotate_780, "Summary_NoRotate_780_Trinidad.csv")
write.csv(Summary_NoRotate_788, "Summary_NoRotate_788_Tunisia.csv")
write.csv(Summary_NoRotate_792, "Summary_NoRotate_792_Turkey.csv")
write.csv(Summary_NoRotate_804, "Summary_NoRotate_804_Ukraine.csv")
write.csv(Summary_NoRotate_858, "Summary_NoRotate_858_Uruguay.csv")
write.csv(Summary_NoRotate_860, "Summary_NoRotate_860_Uzbekistan.csv")
write.csv(Summary_NoRotate_887, "Summary_NoRotate_887_Yemen.csv")
```

###Varimax Rotation
```{r EFA Varimax Loadings & Communalities}
#Now let's look at an varimax rotated loading
Grouped_MIRT_Varimax_Summary <- summary(Grouped_MIRT, rotate="varimax")
#Need to store the coef dataframe under country name
Summary_Names <- paste("Summary_Varimax",unique(Individual_MIRTData$V2.x),sep = "_")
Communalities <- paste("Communalities_Varimax",unique(Individual_MIRTData$V2.x),sep = "_")

n=56
i=1
for(i in 1:n){#loops through the countries
  Country_Loadings <-Grouped_MIRT_Varimax_Summary[[i]] #focuses on one country
  names(Country_Loadings)
  Country_Loadings_Values <- as.data.frame(Country_Loadings$rotF)
  Country_Communalitites <- as.data.frame(Country_Loadings$h2)
  assign(Summary_Names[i], Country_Loadings_Values)
  assign(Communalities[i], Country_Communalitites)
  i=i+1
}
```

```{r Varimax Communality CSV files, eval=FALSE}
Communalities_Varimax <-cbind(Communalities_Varimax_36,  Communalities_Varimax_276, Communalities_Varimax_392,
                               Communalities_Varimax_724, Communalities_Varimax_752, Communalities_Varimax_840,
                               Communalities_Varimax_12,  Communalities_Varimax_31,  Communalities_Varimax_32, 
                               Communalities_Varimax_51,  Communalities_Varimax_76,  Communalities_Varimax_112,
                               Communalities_Varimax_152, Communalities_Varimax_156, Communalities_Varimax_158, 
                               Communalities_Varimax_170, Communalities_Varimax_196, Communalities_Varimax_218,
                               Communalities_Varimax_233, Communalities_Varimax_268, Communalities_Varimax_275,
                               Communalities_Varimax_288, Communalities_Varimax_344, Communalities_Varimax_356,
                               Communalities_Varimax_368, Communalities_Varimax_398, Communalities_Varimax_400,
                               Communalities_Varimax_410, Communalities_Varimax_417, Communalities_Varimax_422,
                               Communalities_Varimax_434, Communalities_Varimax_458, Communalities_Varimax_484,
                               Communalities_Varimax_504, Communalities_Varimax_528, Communalities_Varimax_554,
                               Communalities_Varimax_566, Communalities_Varimax_586, Communalities_Varimax_604, 
                               Communalities_Varimax_608, Communalities_Varimax_616, Communalities_Varimax_642,
                               Communalities_Varimax_643, Communalities_Varimax_646, Communalities_Varimax_702,
                               Communalities_Varimax_705, Communalities_Varimax_710, Communalities_Varimax_716, 
                               Communalities_Varimax_764, Communalities_Varimax_780, Communalities_Varimax_788,
                               Communalities_Varimax_792, Communalities_Varimax_804, Communalities_Varimax_858,
                               Communalities_Varimax_860, Communalities_Varimax_887)

colnames(Communalities_Varimax) <- CountryCodes_Titles
write.csv(Communalities_Varimax, "Communalities_Varimax.csv")
```

Factor Loadings - Since the variance was held to one across all groups the loadings will be exactly the same and there in no need to compare the loadings across countries instead look at the loadings for any random country and compare the different factors.
```{r Varimax F1 Loadings CSV files, eval=FALSE}
#All 56 Countries
F1_Varimax <-cbind(Summary_Varimax_36$F1,  Summary_Varimax_276$F1, Summary_Varimax_392$F1,
                    Summary_Varimax_724$F1, Summary_Varimax_752$F1, Summary_Varimax_840$F1,
                    Summary_Varimax_12$F1,  Summary_Varimax_31$F1,  Summary_Varimax_32$F1, 
                    Summary_Varimax_51$F1,  Summary_Varimax_76$F1,  Summary_Varimax_112$F1,
                    Summary_Varimax_152$F1, Summary_Varimax_156$F1, Summary_Varimax_158$F1, 
                    Summary_Varimax_170$F1, Summary_Varimax_196$F1, Summary_Varimax_218$F1,
                    Summary_Varimax_233$F1, Summary_Varimax_268$F1, Summary_Varimax_275$F1,
                    Summary_Varimax_288$F1, Summary_Varimax_344$F1, Summary_Varimax_356$F1,
                    Summary_Varimax_368$F1, Summary_Varimax_398$F1, Summary_Varimax_400$F1,
                    Summary_Varimax_410$F1, Summary_Varimax_417$F1, Summary_Varimax_422$F1,
                    Summary_Varimax_434$F1, Summary_Varimax_458$F1, Summary_Varimax_484$F1,
                    Summary_Varimax_504$F1, Summary_Varimax_528$F1, Summary_Varimax_554$F1,
                    Summary_Varimax_566$F1, Summary_Varimax_586$F1, Summary_Varimax_604$F1, 
                    Summary_Varimax_608$F1, Summary_Varimax_616$F1, Summary_Varimax_642$F1,
                    Summary_Varimax_643$F1, Summary_Varimax_646$F1, Summary_Varimax_702$F1,
                    Summary_Varimax_705$F1, Summary_Varimax_710$F1, Summary_Varimax_716$F1, 
                    Summary_Varimax_764$F1, Summary_Varimax_780$F1, Summary_Varimax_788$F1,
                    Summary_Varimax_792$F1, Summary_Varimax_804$F1, Summary_Varimax_858$F1,
                    Summary_Varimax_860$F1, Summary_Varimax_887$F1)

colnames(F1_Varimax) <- CountryCodes_Titles
write.csv(F1_Varimax, "F1_Loadings_Varimax.csv")
```

```{r Varimax F2 Loadings CSV files, eval=FALSE}
#All 56 Countries
F2_Varimax <-cbind(Summary_Varimax_36$F2,  Summary_Varimax_276$F2, Summary_Varimax_392$F2,
                    Summary_Varimax_724$F2, Summary_Varimax_752$F2, Summary_Varimax_840$F2,
                    Summary_Varimax_12$F2,  Summary_Varimax_31$F2,  Summary_Varimax_32$F2, 
                    Summary_Varimax_51$F2,  Summary_Varimax_76$F2,  Summary_Varimax_112$F2,
                    Summary_Varimax_152$F2, Summary_Varimax_156$F2, Summary_Varimax_158$F2, 
                    Summary_Varimax_170$F2, Summary_Varimax_196$F2, Summary_Varimax_218$F2,
                    Summary_Varimax_233$F2, Summary_Varimax_268$F2, Summary_Varimax_275$F2,
                    Summary_Varimax_288$F2, Summary_Varimax_344$F2, Summary_Varimax_356$F2,
                    Summary_Varimax_368$F2, Summary_Varimax_398$F2, Summary_Varimax_400$F2,
                    Summary_Varimax_410$F2, Summary_Varimax_417$F2, Summary_Varimax_422$F2,
                    Summary_Varimax_434$F2, Summary_Varimax_458$F2, Summary_Varimax_484$F2,
                    Summary_Varimax_504$F2, Summary_Varimax_528$F2, Summary_Varimax_554$F2,
                    Summary_Varimax_566$F2, Summary_Varimax_586$F2, Summary_Varimax_604$F2, 
                    Summary_Varimax_608$F2, Summary_Varimax_616$F2, Summary_Varimax_642$F2,
                    Summary_Varimax_643$F2, Summary_Varimax_646$F2, Summary_Varimax_702$F2,
                    Summary_Varimax_705$F2, Summary_Varimax_710$F2, Summary_Varimax_716$F2, 
                    Summary_Varimax_764$F2, Summary_Varimax_780$F2, Summary_Varimax_788$F2,
                    Summary_Varimax_792$F2, Summary_Varimax_804$F2, Summary_Varimax_858$F2,
                    Summary_Varimax_860$F2, Summary_Varimax_887$F2)

colnames(F2_Varimax) <- CountryCodes_Titles
write.csv(F2_Varimax, "F2_Loadings_Varimax.csv")
```

```{r Varimax F3 Loadings CSV files, eval=FALSE}
#All 56 Countries
F3_Varimax <-cbind(Summary_Varimax_36$F3,  Summary_Varimax_276$F3, Summary_Varimax_392$F3,
                    Summary_Varimax_724$F3, Summary_Varimax_752$F3, Summary_Varimax_840$F3,
                    Summary_Varimax_12$F3,  Summary_Varimax_31$F3,  Summary_Varimax_32$F3, 
                    Summary_Varimax_51$F3,  Summary_Varimax_76$F3,  Summary_Varimax_112$F3,
                    Summary_Varimax_152$F3, Summary_Varimax_156$F3, Summary_Varimax_158$F3, 
                    Summary_Varimax_170$F3, Summary_Varimax_196$F3, Summary_Varimax_218$F3,
                    Summary_Varimax_233$F3, Summary_Varimax_268$F3, Summary_Varimax_275$F3,
                    Summary_Varimax_288$F3, Summary_Varimax_344$F3, Summary_Varimax_356$F3,
                    Summary_Varimax_368$F3, Summary_Varimax_398$F3, Summary_Varimax_400$F3,
                    Summary_Varimax_410$F3, Summary_Varimax_417$F3, Summary_Varimax_422$F3,
                    Summary_Varimax_434$F3, Summary_Varimax_458$F3, Summary_Varimax_484$F3,
                    Summary_Varimax_504$F3, Summary_Varimax_528$F3, Summary_Varimax_554$F3,
                    Summary_Varimax_566$F3, Summary_Varimax_586$F3, Summary_Varimax_604$F3, 
                    Summary_Varimax_608$F3, Summary_Varimax_616$F3, Summary_Varimax_642$F3,
                    Summary_Varimax_643$F3, Summary_Varimax_646$F3, Summary_Varimax_702$F3,
                    Summary_Varimax_705$F3, Summary_Varimax_710$F3, Summary_Varimax_716$F3, 
                    Summary_Varimax_764$F3, Summary_Varimax_780$F3, Summary_Varimax_788$F3,
                    Summary_Varimax_792$F3, Summary_Varimax_804$F3, Summary_Varimax_858$F3,
                    Summary_Varimax_860$F3, Summary_Varimax_887$F3)

colnames(F3_Varimax) <- CountryCodes_Titles
write.csv(F3_Varimax, "F3_Loadings_Varimax.csv")
```

```{r Varimax F4 Loadings CSV files, eval=FALSE}
#All 56 Countries
F4_Varimax <-cbind(Summary_Varimax_36$F4,  Summary_Varimax_276$F4, Summary_Varimax_392$F4,
                    Summary_Varimax_724$F4, Summary_Varimax_752$F4, Summary_Varimax_840$F4,
                    Summary_Varimax_12$F4,  Summary_Varimax_31$F4,  Summary_Varimax_32$F4, 
                    Summary_Varimax_51$F4,  Summary_Varimax_76$F4,  Summary_Varimax_112$F4,
                    Summary_Varimax_152$F4, Summary_Varimax_156$F4, Summary_Varimax_158$F4, 
                    Summary_Varimax_170$F4, Summary_Varimax_196$F4, Summary_Varimax_218$F4,
                    Summary_Varimax_233$F4, Summary_Varimax_268$F4, Summary_Varimax_275$F4,
                    Summary_Varimax_288$F4, Summary_Varimax_344$F4, Summary_Varimax_356$F4,
                    Summary_Varimax_368$F4, Summary_Varimax_398$F4, Summary_Varimax_400$F4,
                    Summary_Varimax_410$F4, Summary_Varimax_417$F4, Summary_Varimax_422$F4,
                    Summary_Varimax_434$F4, Summary_Varimax_458$F4, Summary_Varimax_484$F4,
                    Summary_Varimax_504$F4, Summary_Varimax_528$F4, Summary_Varimax_554$F4,
                    Summary_Varimax_566$F4, Summary_Varimax_586$F4, Summary_Varimax_604$F4, 
                    Summary_Varimax_608$F4, Summary_Varimax_616$F4, Summary_Varimax_642$F4,
                    Summary_Varimax_643$F4, Summary_Varimax_646$F4, Summary_Varimax_702$F4,
                    Summary_Varimax_705$F4, Summary_Varimax_710$F4, Summary_Varimax_716$F4, 
                    Summary_Varimax_764$F4, Summary_Varimax_780$F4, Summary_Varimax_788$F4,
                    Summary_Varimax_792$F4, Summary_Varimax_804$F4, Summary_Varimax_858$F4,
                    Summary_Varimax_860$F4, Summary_Varimax_887$F4)

colnames(F4_Varimax) <- CountryCodes_Titles
write.csv(F4_Varimax, "F4_Loadings_Varimax.csv")
```

Check that all countries have the same loading
```{r Check All Countries are Equal}
summary(Summary_Varimax_112==Summary_Varimax_196)
```

```{r All Factor Loadings by Country Varimax csv files, eval=FALSE}
#All the loadings should be the same if the variation was held to one
write.csv(Summary_Varimax_36, "Summary_Varimax_36_Austrailia.csv")
write.csv(Summary_Varimax_276, "Summary_Varimax_276_Germany.csv")
write.csv(Summary_Varimax_392, "Summary_Varimax_392_Japan.csv")
write.csv(Summary_Varimax_724, "Summary_Varimax_724_Spain.csv")
write.csv(Summary_Varimax_752, "Summary_Varimax_752_Sweden.csv")
write.csv(Summary_Varimax_840, "Summary_Varimax_840_UnitedStates.csv")

write.csv(Summary_Varimax_12, "Summary_Varimax_12_Algeria.csv")
write.csv(Summary_Varimax_31, "Summary_Varimax_31_Azerbaijan.csv")
write.csv(Summary_Varimax_32, "Summary_Varimax_32_Argentina.csv")
write.csv(Summary_Varimax_51, "Summary_Varimax_51_Armenia.csv")
write.csv(Summary_Varimax_76, "Summary_Varimax_76_Brazil.csv")
write.csv(Summary_Varimax_112,"Summary_Varimax_112_Belarus.csv")
write.csv(Summary_Varimax_152,"Summary_Varimax_152_Chile.csv")
write.csv(Summary_Varimax_156, "Summary_Varimax_156_China.csv")
write.csv(Summary_Varimax_158, "Summary_Varimax_158_Taiwan.csv")
write.csv(Summary_Varimax_170, "Summary_Varimax_170_Colombia.csv")
write.csv(Summary_Varimax_196, "Summary_Varimax_196_Cyprus.csv")
write.csv(Summary_Varimax_218, "Summary_Varimax_218_Equador.csv")
write.csv(Summary_Varimax_233, "Summary_Varimax_233_Estonia.csv")
write.csv(Summary_Varimax_268, "Summary_Varimax_268_Georgia.csv")
write.csv(Summary_Varimax_275, "Summary_Varimax_275_Palestine.csv")
write.csv(Summary_Varimax_288, "Summary_Varimax_288_Ghana.csv")
write.csv(Summary_Varimax_344, "Summary_Varimax_344_HongKong.csv")
write.csv(Summary_Varimax_356, "Summary_Varimax_356_India.csv")
write.csv(Summary_Varimax_368, "Summary_Varimax_368_Iraq.csv")
write.csv(Summary_Varimax_398, "Summary_Varimax_398_Kazakhstan.csv")
write.csv(Summary_Varimax_400, "Summary_Varimax_400_Jordan.csv")
write.csv(Summary_Varimax_410, "Summary_Varimax_410_SouthKorea.csv")
write.csv(Summary_Varimax_417, "Summary_Varimax_417_Kyrgyzstan.csv")
write.csv(Summary_Varimax_422, "Summary_Varimax_422_Lebanon.csv")
write.csv(Summary_Varimax_434, "Summary_Varimax_434_Libya.csv")
write.csv(Summary_Varimax_458, "Summary_Varimax_458_Malaysia.csv")
write.csv(Summary_Varimax_484, "Summary_Varimax_484_Mexico.csv")
write.csv(Summary_Varimax_504, "Summary_Varimax_504_Morocco.csv")
write.csv(Summary_Varimax_528, "Summary_Varimax_528_Netherlands.csv")
write.csv(Summary_Varimax_554, "Summary_Varimax_554_NewZealand.csv")
write.csv(Summary_Varimax_566, "Summary_Varimax_566_Nigeria.csv")
write.csv(Summary_Varimax_586, "Summary_Varimax_586_Pakistan.csv")
write.csv(Summary_Varimax_604, "Summary_Varimax_604_Peru.csv")
write.csv(Summary_Varimax_608, "Summary_Varimax_608_Phillipines.csv")
write.csv(Summary_Varimax_616, "Summary_Varimax_616_Poland.csv")
write.csv(Summary_Varimax_642, "Summary_Varimax_642_Romania.csv")
write.csv(Summary_Varimax_643, "Summary_Varimax_643_Russia.csv")
write.csv(Summary_Varimax_646, "Summary_Varimax_646_Rwanda.csv")
write.csv(Summary_Varimax_702, "Summary_Varimax_702_Singapore.csv")
write.csv(Summary_Varimax_705, "Summary_Varimax_705_Slovenia.csv")
write.csv(Summary_Varimax_710, "Summary_Varimax_710_SouthAfrica.csv")
write.csv(Summary_Varimax_716, "Summary_Varimax_716_Zimbabwe.csv")
write.csv(Summary_Varimax_764, "Summary_Varimax_764_Thailand.csv")
write.csv(Summary_Varimax_780, "Summary_Varimax_780_Trinidad.csv")
write.csv(Summary_Varimax_788, "Summary_Varimax_788_Tunisia.csv")
write.csv(Summary_Varimax_792, "Summary_Varimax_792_Turkey.csv")
write.csv(Summary_Varimax_804, "Summary_Varimax_804_Ukraine.csv")
write.csv(Summary_Varimax_858, "Summary_Varimax_858_Uruguay.csv")
write.csv(Summary_Varimax_860, "Summary_Varimax_860_Uzbekistan.csv")
write.csv(Summary_Varimax_887, "Summary_Varimax_887_Yemen.csv")
```

###Oblimin Rotation
```{r Oblimin  Loadings & Communalities}
#Now let's look at an oblimin rotated loading
Grouped_MIRT_Model_All_Countries_Summary <- summary(Grouped_MIRT, rotate="oblimin", verbose=F)
#Need to store the coef dataframe under country name
Summary_Names <- paste("Summary_Oblimin",unique(Individual_MIRTData$V2.x),sep = "_")
Communalities <- paste("Communalities_Oblimin",unique(Individual_MIRTData$V2.x),sep = "_")

i=1
for(i in 1:n){#loops through the countries
  Country_Loadings <-Grouped_MIRT_Model_All_Countries_Summary[[i]] #focuses on one country
  names(Country_Loadings)
  Country_Loadings_Values <- as.data.frame(Country_Loadings$rotF)
  Country_Communalitites <- as.data.frame(Country_Loadings$h2)
  assign(Summary_Names[i], Country_Loadings_Values)
  assign(Communalities[i], Country_Communalitites)
  i=i+1
}
```

```{r Oblimin Communality CSV files, eval=FALSE}
Communalities_Oblimin <-cbind(Communalities_Oblimin_36, Communalities_Oblimin_276, 
                              Communalities_Oblimin_392,Communalities_Oblimin_724, 
                              Communalities_Oblimin_752,Communalities_Oblimin_840,
                              Communalities_Oblimin_12, Communalities_Oblimin_31,  
                              Communalities_Oblimin_32, Communalities_Oblimin_51,  
                              Communalities_Oblimin_76, Communalities_Oblimin_112,
                              Communalities_Oblimin_152,Communalities_Oblimin_156, 
                              Communalities_Oblimin_158,Communalities_Oblimin_170, 
                              Communalities_Oblimin_196, Communalities_Oblimin_218,
                               Communalities_Oblimin_233, Communalities_Oblimin_268,
                              Communalities_Oblimin_275,
                               Communalities_Oblimin_288, Communalities_Oblimin_344, Communalities_Oblimin_356,
                               Communalities_Oblimin_368, Communalities_Oblimin_398, Communalities_Oblimin_400,
                               Communalities_Oblimin_410, Communalities_Oblimin_417, Communalities_Oblimin_422,
                               Communalities_Oblimin_434, Communalities_Oblimin_458, Communalities_Oblimin_484,
                               Communalities_Oblimin_504, Communalities_Oblimin_528, Communalities_Oblimin_554,
                               Communalities_Oblimin_566, Communalities_Oblimin_586, Communalities_Oblimin_604, 
                               Communalities_Oblimin_608, Communalities_Oblimin_616, Communalities_Oblimin_642,
                               Communalities_Oblimin_643, Communalities_Oblimin_646, Communalities_Oblimin_702,
                               Communalities_Oblimin_705, Communalities_Oblimin_710, Communalities_Oblimin_716, 
                               Communalities_Oblimin_764, Communalities_Oblimin_780, Communalities_Oblimin_788,
                               Communalities_Oblimin_792, Communalities_Oblimin_804, Communalities_Oblimin_858,
                               Communalities_Oblimin_860, Communalities_Oblimin_887)

colnames(Communalities_Oblimin) <- CountryCodes_Titles
write.csv(Communalities_Oblimin, "Communalities_Oblimin_SciEqu_56C_SLM.csv")
```

Factor Loadings - Since the variance was held to one across all groups the loadings will be exactly the same and there in no need to compare the loadings across countries instead look at the loadings for any random country and compare the different factors.
```{r Oblimin F1 Loadings CSV files}
#All 56 Countries
F1_Oblimin <-cbind(Summary_Oblimin_36$F1,  Summary_Oblimin_276$F1, Summary_Oblimin_392$F1,
                    Summary_Oblimin_724$F1, Summary_Oblimin_752$F1, Summary_Oblimin_840$F1,
                    Summary_Oblimin_12$F1,  Summary_Oblimin_31$F1,  Summary_Oblimin_32$F1, 
                    Summary_Oblimin_51$F1,  Summary_Oblimin_76$F1,  Summary_Oblimin_112$F1,
                    Summary_Oblimin_152$F1, Summary_Oblimin_156$F1, Summary_Oblimin_158$F1, 
                    Summary_Oblimin_170$F1, Summary_Oblimin_196$F1, Summary_Oblimin_218$F1,
                    Summary_Oblimin_233$F1, Summary_Oblimin_268$F1, Summary_Oblimin_275$F1,
                    Summary_Oblimin_288$F1, Summary_Oblimin_344$F1, Summary_Oblimin_356$F1,
                    Summary_Oblimin_368$F1, Summary_Oblimin_398$F1, Summary_Oblimin_400$F1,
                    Summary_Oblimin_410$F1, Summary_Oblimin_417$F1, Summary_Oblimin_422$F1,
                    Summary_Oblimin_434$F1, Summary_Oblimin_458$F1, Summary_Oblimin_484$F1,
                    Summary_Oblimin_504$F1, Summary_Oblimin_528$F1, Summary_Oblimin_554$F1,
                    Summary_Oblimin_566$F1, Summary_Oblimin_586$F1, Summary_Oblimin_604$F1, 
                    Summary_Oblimin_608$F1, Summary_Oblimin_616$F1, Summary_Oblimin_642$F1,
                    Summary_Oblimin_643$F1, Summary_Oblimin_646$F1, Summary_Oblimin_702$F1,
                    Summary_Oblimin_705$F1, Summary_Oblimin_710$F1, Summary_Oblimin_716$F1, 
                    Summary_Oblimin_764$F1, Summary_Oblimin_780$F1, Summary_Oblimin_788$F1,
                    Summary_Oblimin_792$F1, Summary_Oblimin_804$F1, Summary_Oblimin_858$F1,
                    Summary_Oblimin_860$F1, Summary_Oblimin_887$F1)

colnames(F1_Oblimin) <- CountryCodes_Titles
write.csv(F1_Oblimin, "F1_Loadings_Oblimin.csv")
```

```{r Oblimin F2 Loadings CSV files}
#Factor 2 (F2) - All 56 Countries
F2_Oblimin <-cbind(Summary_Oblimin_36$F2,  Summary_Oblimin_276$F2, Summary_Oblimin_392$F2,
                    Summary_Oblimin_724$F2, Summary_Oblimin_752$F2, Summary_Oblimin_840$F2,
                    Summary_Oblimin_12$F2,  Summary_Oblimin_31$F2,  Summary_Oblimin_32$F2, 
                    Summary_Oblimin_51$F2,  Summary_Oblimin_76$F2,  Summary_Oblimin_112$F2,
                    Summary_Oblimin_152$F2, Summary_Oblimin_156$F2, Summary_Oblimin_158$F2, 
                    Summary_Oblimin_170$F2, Summary_Oblimin_196$F2, Summary_Oblimin_218$F2,
                    Summary_Oblimin_233$F2, Summary_Oblimin_268$F2, Summary_Oblimin_275$F2,
                    Summary_Oblimin_288$F2, Summary_Oblimin_344$F2, Summary_Oblimin_356$F2,
                    Summary_Oblimin_368$F2, Summary_Oblimin_398$F2, Summary_Oblimin_400$F2,
                    Summary_Oblimin_410$F2, Summary_Oblimin_417$F2, Summary_Oblimin_422$F2,
                    Summary_Oblimin_434$F2, Summary_Oblimin_458$F2, Summary_Oblimin_484$F2,
                    Summary_Oblimin_504$F2, Summary_Oblimin_528$F2, Summary_Oblimin_554$F2,
                    Summary_Oblimin_566$F2, Summary_Oblimin_586$F2, Summary_Oblimin_604$F2, 
                    Summary_Oblimin_608$F2, Summary_Oblimin_616$F2, Summary_Oblimin_642$F2,
                    Summary_Oblimin_643$F2, Summary_Oblimin_646$F2, Summary_Oblimin_702$F2,
                    Summary_Oblimin_705$F2, Summary_Oblimin_710$F2, Summary_Oblimin_716$F2, 
                    Summary_Oblimin_764$F2, Summary_Oblimin_780$F2, Summary_Oblimin_788$F2,
                    Summary_Oblimin_792$F2, Summary_Oblimin_804$F2, Summary_Oblimin_858$F2,
                    Summary_Oblimin_860$F2, Summary_Oblimin_887$F2)

colnames(F2_Oblimin) <- CountryCodes_Titles
write.csv(F2_Oblimin, "F2_Loadings_Oblimin.csv")
```

```{r Oblimin F3 Loadings CSV files}
#F3 (CD3) Oblimin - All 56 Countries
F3_Oblimin <-cbind(Summary_Oblimin_36$F3,  Summary_Oblimin_276$F3, Summary_Oblimin_392$F3,
                    Summary_Oblimin_724$F3, Summary_Oblimin_752$F3, Summary_Oblimin_840$F3,
                    Summary_Oblimin_12$F3,  Summary_Oblimin_31$F3,  Summary_Oblimin_32$F3, 
                    Summary_Oblimin_51$F3,  Summary_Oblimin_76$F3,  Summary_Oblimin_112$F3,
                    Summary_Oblimin_152$F3, Summary_Oblimin_156$F3, Summary_Oblimin_158$F3, 
                    Summary_Oblimin_170$F3, Summary_Oblimin_196$F3, Summary_Oblimin_218$F3,
                    Summary_Oblimin_233$F3, Summary_Oblimin_268$F3, Summary_Oblimin_275$F3,
                    Summary_Oblimin_288$F3, Summary_Oblimin_344$F3, Summary_Oblimin_356$F3,
                    Summary_Oblimin_368$F3, Summary_Oblimin_398$F3, Summary_Oblimin_400$F3,
                    Summary_Oblimin_410$F3, Summary_Oblimin_417$F3, Summary_Oblimin_422$F3,
                    Summary_Oblimin_434$F3, Summary_Oblimin_458$F3, Summary_Oblimin_484$F3,
                    Summary_Oblimin_504$F3, Summary_Oblimin_528$F3, Summary_Oblimin_554$F3,
                    Summary_Oblimin_566$F3, Summary_Oblimin_586$F3, Summary_Oblimin_604$F3, 
                    Summary_Oblimin_608$F3, Summary_Oblimin_616$F3, Summary_Oblimin_642$F3,
                    Summary_Oblimin_643$F3, Summary_Oblimin_646$F3, Summary_Oblimin_702$F3,
                    Summary_Oblimin_705$F3, Summary_Oblimin_710$F3, Summary_Oblimin_716$F3, 
                    Summary_Oblimin_764$F3, Summary_Oblimin_780$F3, Summary_Oblimin_788$F3,
                    Summary_Oblimin_792$F3, Summary_Oblimin_804$F3, Summary_Oblimin_858$F3,
                    Summary_Oblimin_860$F3, Summary_Oblimin_887$F3)

colnames(F3_Oblimin) <- CountryCodes_Titles
write.csv(F3_Oblimin, "F3_Loadings_Oblimin.csv")
```

```{r Oblimin F4 Loadings CSV files}
#F4_Oblimin (CD4) - All 56 Countries
F4_Oblimin <-cbind(Summary_Oblimin_36$F4,  Summary_Oblimin_276$F4, Summary_Oblimin_392$F4,
                    Summary_Oblimin_724$F4, Summary_Oblimin_752$F4, Summary_Oblimin_840$F4,
                    Summary_Oblimin_12$F4,  Summary_Oblimin_31$F4,  Summary_Oblimin_32$F4, 
                    Summary_Oblimin_51$F4,  Summary_Oblimin_76$F4,  Summary_Oblimin_112$F4,
                    Summary_Oblimin_152$F4, Summary_Oblimin_156$F4, Summary_Oblimin_158$F4, 
                    Summary_Oblimin_170$F4, Summary_Oblimin_196$F4, Summary_Oblimin_218$F4,
                    Summary_Oblimin_233$F4, Summary_Oblimin_268$F4, Summary_Oblimin_275$F4,
                    Summary_Oblimin_288$F4, Summary_Oblimin_344$F4, Summary_Oblimin_356$F4,
                    Summary_Oblimin_368$F4, Summary_Oblimin_398$F4, Summary_Oblimin_400$F4,
                    Summary_Oblimin_410$F4, Summary_Oblimin_417$F4, Summary_Oblimin_422$F4,
                    Summary_Oblimin_434$F4, Summary_Oblimin_458$F4, Summary_Oblimin_484$F4,
                    Summary_Oblimin_504$F4, Summary_Oblimin_528$F4, Summary_Oblimin_554$F4,
                    Summary_Oblimin_566$F4, Summary_Oblimin_586$F4, Summary_Oblimin_604$F4, 
                    Summary_Oblimin_608$F4, Summary_Oblimin_616$F4, Summary_Oblimin_642$F4,
                    Summary_Oblimin_643$F4, Summary_Oblimin_646$F4, Summary_Oblimin_702$F4,
                    Summary_Oblimin_705$F4, Summary_Oblimin_710$F4, Summary_Oblimin_716$F4, 
                    Summary_Oblimin_764$F4, Summary_Oblimin_780$F4, Summary_Oblimin_788$F4,
                    Summary_Oblimin_792$F4, Summary_Oblimin_804$F4, Summary_Oblimin_858$F4,
                    Summary_Oblimin_860$F4, Summary_Oblimin_887$F4)

colnames(F4_Oblimin) <- CountryCodes_Titles
write.csv(F4_Oblimin, "F4_Loadings_Oblimin.csv")
```

```{r All Factor Loadings by Country Oblimin csv files, eval=FALSE}
#All the loadings should be the same if the variation was held to one
write.csv(Summary_Oblimin_36, "Summary_Oblimin_36_Austrailia.csv")
write.csv(Summary_Oblimin_276, "Summary_Oblimin_276_Germany.csv")
write.csv(Summary_Oblimin_392, "Summary_Oblimin_392_Japan.csv")
write.csv(Summary_Oblimin_724, "Summary_Oblimin_724_Spain.csv")
write.csv(Summary_Oblimin_752, "Summary_Oblimin_752_Sweden.csv")
write.csv(Summary_Oblimin_840, "Summary_Oblimin_840_UnitedStates.csv")

write.csv(Summary_Oblimin_12, "Summary_Oblimin_12_Algeria.csv")
write.csv(Summary_Oblimin_31, "Summary_Oblimin_31_Azerbaijan.csv")
write.csv(Summary_Oblimin_32, "Summary_Oblimin_32_Argentina.csv")
write.csv(Summary_Oblimin_51, "Summary_Oblimin_51_Armenia.csv")
write.csv(Summary_Oblimin_76, "Summary_Oblimin_76_Brazil.csv")
write.csv(Summary_Oblimin_112,"Summary_Oblimin_112_Belarus.csv")
write.csv(Summary_Oblimin_152,"Summary_Oblimin_152_Chile.csv")
write.csv(Summary_Oblimin_156, "Summary_Oblimin_156_China.csv")
write.csv(Summary_Oblimin_158, "Summary_Oblimin_158_Taiwan.csv")
write.csv(Summary_Oblimin_170, "Summary_Oblimin_170_Colombia.csv")
write.csv(Summary_Oblimin_196, "Summary_Oblimin_196_Cyprus.csv")
write.csv(Summary_Oblimin_218, "Summary_Oblimin_218_Equador.csv")
write.csv(Summary_Oblimin_233, "Summary_Oblimin_233_Estonia.csv")
write.csv(Summary_Oblimin_268, "Summary_Oblimin_268_Georgia.csv")
write.csv(Summary_Oblimin_275, "Summary_Oblimin_275_Palestine.csv")
write.csv(Summary_Oblimin_288, "Summary_Oblimin_288_Ghana.csv")
write.csv(Summary_Oblimin_344, "Summary_Oblimin_344_HongKong.csv")
write.csv(Summary_Oblimin_356, "Summary_Oblimin_356_India.csv")
write.csv(Summary_Oblimin_368, "Summary_Oblimin_368_Iraq.csv")
write.csv(Summary_Oblimin_398, "Summary_Oblimin_398_Kazakhstan.csv")
write.csv(Summary_Oblimin_400, "Summary_Oblimin_400_Jordan.csv")
write.csv(Summary_Oblimin_410, "Summary_Oblimin_410_SouthKorea.csv")
write.csv(Summary_Oblimin_417, "Summary_Oblimin_417_Kyrgyzstan.csv")
write.csv(Summary_Oblimin_422, "Summary_Oblimin_422_Lebanon.csv")
write.csv(Summary_Oblimin_434, "Summary_Oblimin_434_Libya.csv")
write.csv(Summary_Oblimin_458, "Summary_Oblimin_458_Malaysia.csv")
write.csv(Summary_Oblimin_484, "Summary_Oblimin_484_Mexico.csv")
write.csv(Summary_Oblimin_504, "Summary_Oblimin_504_Morocco.csv")
write.csv(Summary_Oblimin_528, "Summary_Oblimin_528_Netherlands.csv")
write.csv(Summary_Oblimin_554, "Summary_Oblimin_554_NewZealand.csv")
write.csv(Summary_Oblimin_566, "Summary_Oblimin_566_Nigeria.csv")
write.csv(Summary_Oblimin_586, "Summary_Oblimin_586_Pakistan.csv")
write.csv(Summary_Oblimin_604, "Summary_Oblimin_604_Peru.csv")
write.csv(Summary_Oblimin_608, "Summary_Oblimin_608_Phillipines.csv")
write.csv(Summary_Oblimin_616, "Summary_Oblimin_616_Poland.csv")
write.csv(Summary_Oblimin_642, "Summary_Oblimin_642_Romania.csv")
write.csv(Summary_Oblimin_643, "Summary_Oblimin_643_Russia.csv")
write.csv(Summary_Oblimin_646, "Summary_Oblimin_646_Rwanda.csv")
write.csv(Summary_Oblimin_702, "Summary_Oblimin_702_Singapore.csv")
write.csv(Summary_Oblimin_705, "Summary_Oblimin_705_Slovenia.csv")
write.csv(Summary_Oblimin_710, "Summary_Oblimin_710_SouthAfrica.csv")
write.csv(Summary_Oblimin_716, "Summary_Oblimin_716_Zimbabwe.csv")
write.csv(Summary_Oblimin_764, "Summary_Oblimin_764_Thailand.csv")
write.csv(Summary_Oblimin_780, "Summary_Oblimin_780_Trinidad.csv")
write.csv(Summary_Oblimin_788, "Summary_Oblimin_788_Tunisia.csv")
write.csv(Summary_Oblimin_792, "Summary_Oblimin_792_Turkey.csv")
write.csv(Summary_Oblimin_804, "Summary_Oblimin_804_Ukraine.csv")
write.csv(Summary_Oblimin_858, "Summary_Oblimin_858_Uruguay.csv")
write.csv(Summary_Oblimin_860, "Summary_Oblimin_860_Uzbekistan.csv")
write.csv(Summary_Oblimin_887, "Summary_Oblimin_887_Yemen.csv")
```

#Factor Scores
Now we calculate the scores of each INDIVIDUAL on the discovered latent dimensions. These individual scores will be used to create an average for the entire country. 
```{r Individual EFA Factor Scores All Rotations, eval=FALSE}
#Now lets look at factor scores for individuals seperately
#No Rotation
Scores_All_NoRotate <- cbind(Individual_MIRTData_test$V2.x,
                            fscores(Grouped_MIRT, rotate = "none", method = "MAP"))
write.csv(Scores_All_NoRotate, "Scores_All_NoRotate.csv")

#Varimax Rotation
Scores_All_Varimax<- cbind(Individual_MIRTData_test$V2.x,
                            fscores(Grouped_MIRT, rotate = "varimax", method = "MAP"))

Scores_All_Varimax2<-fscores(Grouped_MIRT, rotate = "varimax", method = "MAP",full.scores.SE=TRUE)


write.csv(Scores_All_Varimax, "Scores_All_Varimax.csv")

#Oblimin Rotation
Scores_All_Oblimin<-cbind(Individual_MIRTData_test$V2.x,
                          fscores(Grouped_MIRT, rotate = "oblimin", QMC=TRUE))
write.csv(Scores_All_Oblimin, "Scores_All_Oblimin.csv")
```